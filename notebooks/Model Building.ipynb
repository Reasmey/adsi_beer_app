{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "https://www.kaggle.com/vadbeg/pytorch-nn-with-embeddings-and-catboost/notebook#PyTorch\n",
    "\n",
    "mostly based off this example, plus parts of code form tutorial 5 lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data function from \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fix system path\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministick = True\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    \n",
    "set_seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317320, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951959, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317320, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89700000e+03,  3.78951241e-01,  1.06859912e+00,\n",
       "         1.84150005e+00,  9.66077605e-01],\n",
       "       [ 4.91800000e+03, -3.20469239e+00, -2.17768163e+00,\n",
       "        -3.57227099e-01, -4.00106932e-01],\n",
       "       [ 1.70100000e+03, -3.37777485e-01,  2.57028931e-01,\n",
       "        -3.57227099e-01, -4.00106932e-01],\n",
       "       ...,\n",
       "       [ 4.59800000e+03,  1.09567997e+00,  2.57028931e-01,\n",
       "        -3.57227099e-01,  2.82985337e-01],\n",
       "       [ 3.18900000e+03,  3.78951241e-01,  1.06859912e+00,\n",
       "         3.75681950e-01,  2.82985337e-01],\n",
       "       [ 9.70000000e+01,  3.78951241e-01, -2.17768163e+00,\n",
       "        -3.57227099e-01,  2.82985337e-01]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert to tensors\n",
    "from src.models.pytorch import EmbeddingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(X_train, \n",
    "                                      targets=y_train,\n",
    "                                      cat_cols_idx=[0],\n",
    "                                      cont_cols_idx=[1,2,3,4])\n",
    "\n",
    "val_dataset = EmbeddingDataset(X_val, \n",
    "                                      targets=y_val,\n",
    "                                      cat_cols_idx=[0],\n",
    "                                      cont_cols_idx=[1,2,3,4])\n",
    "\n",
    "\n",
    "test_dataset = EmbeddingDataset(X_test,\n",
    "                                     cat_cols_idx=[0],\n",
    "                                     cont_cols_idx=[1,2,3,4],\n",
    "                                     is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of train_dataset: {'data': [tensor([4918.]), tensor([-3.2047, -2.1777, -0.3572, -0.4001])], 'target': tensor(13)}\n",
      "First element of val_dataset: {'data': [tensor([163.]), tensor([-1.0545, -0.5545, -1.0901, -1.0832])], 'target': tensor(31)}\n",
      "First element of test_dataset: {'data': [tensor([701.]), tensor([ 0.3790,  0.2570,  0.3757, -0.4001])]}\n"
     ]
    }
   ],
   "source": [
    "print(f'First element of train_dataset: {train_dataset[1]}',\n",
    "      f'First element of val_dataset: {val_dataset[1]}',\n",
    "      f'First element of test_dataset: {test_dataset[1]}',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding example\n",
    "class ClassificationEmbdNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dims, no_of_cont=None):\n",
    "        super(ClassificationEmbdNN, self).__init__()\n",
    "        \n",
    "        self.emb_layers = torch.nn.ModuleList([torch.nn.Embedding(x, y)\n",
    "                                               for x, y in emb_dims])\n",
    "        \n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.emb_dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.no_of_cont = 0\n",
    "        if no_of_cont:\n",
    "            self.no_of_cont = no_of_cont\n",
    "            self.bn_cont = torch.nn.BatchNorm1d(no_of_cont)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=self.no_of_embs + self.no_of_cont, \n",
    "                                   out_features=208)\n",
    "        self.dropout1 = torch.nn.Dropout(0.2)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(208)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(in_features=208, \n",
    "                                   out_features=208)\n",
    "        self.dropout2 = torch.nn.Dropout(0.2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(208)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        \n",
    "#         self.fc3 = torch.nn.Linear(in_features=256, \n",
    "#                                    out_features=64)\n",
    "#         self.dropout3 = torch.nn.Dropout(0.2)\n",
    "#         self.bn3 = torch.nn.BatchNorm1d(64)\n",
    "#         self.act3 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(in_features=208, \n",
    "                                   out_features=104)\n",
    "        self.act3 = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x_cat, x_cont=None):\n",
    "        if self.no_of_embs != 0:\n",
    "            x = [emb_layer(x_cat[:, i])\n",
    "                 for i, emb_layer in enumerate(self.emb_layers)]\n",
    "        \n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_dropout(x)\n",
    "            \n",
    "        if self.no_of_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            \n",
    "            if self.no_of_embs != 0:\n",
    "                x = torch.cat([x, x_cont], 1)\n",
    "            else:\n",
    "                x = x_cont\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "#         x = self.fc3(x)\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.bn3(x)\n",
    "#         x = self.act3(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationEmbdNN(emb_dims=[[5742, 252]], \n",
    "                             no_of_cont=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationEmbdNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(5742, 252)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=208, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (bn1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=208, out_features=208, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU()\n",
       "  (fc3): Linear(in_features=208, out_features=104, bias=True)\n",
       "  (act3): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationEmbdNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(5742, 252)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=208, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (bn1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=208, out_features=208, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU()\n",
       "  (fc3): Linear(in_features=208, out_features=104, bias=True)\n",
       "  (act3): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# train_sampler = SubsetRandomSampler(X_train)\n",
    "\n",
    "# valid_sampler = SubsetRandomSampler(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [tensor([[4950.],\n",
       "          [ 701.],\n",
       "          [4838.],\n",
       "          [3623.],\n",
       "          [4743.],\n",
       "          [1212.],\n",
       "          [4538.],\n",
       "          [5607.],\n",
       "          [5669.],\n",
       "          [4950.],\n",
       "          [4950.],\n",
       "          [2368.],\n",
       "          [3884.],\n",
       "          [4717.],\n",
       "          [5115.],\n",
       "          [4581.],\n",
       "          [ 819.],\n",
       "          [2112.],\n",
       "          [3775.],\n",
       "          [4489.],\n",
       "          [4838.],\n",
       "          [5472.],\n",
       "          [1278.],\n",
       "          [3260.],\n",
       "          [4743.],\n",
       "          [5003.],\n",
       "          [ 528.],\n",
       "          [ 177.],\n",
       "          [5597.],\n",
       "          [1182.],\n",
       "          [1238.],\n",
       "          [2909.],\n",
       "          [ 375.],\n",
       "          [4074.],\n",
       "          [1334.],\n",
       "          [1879.],\n",
       "          [ 701.],\n",
       "          [ 235.],\n",
       "          [1251.],\n",
       "          [5392.],\n",
       "          [1963.],\n",
       "          [ 482.],\n",
       "          [ 701.],\n",
       "          [5078.],\n",
       "          [ 235.],\n",
       "          [ 148.],\n",
       "          [4489.],\n",
       "          [3438.],\n",
       "          [ 144.],\n",
       "          [3431.],\n",
       "          [5115.],\n",
       "          [1168.],\n",
       "          [ 707.],\n",
       "          [ 708.],\n",
       "          [3556.],\n",
       "          [3601.],\n",
       "          [2323.],\n",
       "          [5330.],\n",
       "          [5695.],\n",
       "          [2239.],\n",
       "          [4863.],\n",
       "          [3082.],\n",
       "          [5392.],\n",
       "          [4860.],\n",
       "          [1247.],\n",
       "          [5531.],\n",
       "          [2698.],\n",
       "          [2967.],\n",
       "          [3208.],\n",
       "          [2207.],\n",
       "          [5103.],\n",
       "          [5582.],\n",
       "          [3512.],\n",
       "          [ 355.],\n",
       "          [3841.],\n",
       "          [ 704.],\n",
       "          [2262.],\n",
       "          [5016.],\n",
       "          [3235.],\n",
       "          [2461.],\n",
       "          [4794.],\n",
       "          [1989.],\n",
       "          [5104.],\n",
       "          [2239.],\n",
       "          [4280.],\n",
       "          [ 361.],\n",
       "          [4831.],\n",
       "          [4798.],\n",
       "          [ 104.],\n",
       "          [ 360.],\n",
       "          [  88.],\n",
       "          [1502.],\n",
       "          [2233.],\n",
       "          [ 793.],\n",
       "          [1933.],\n",
       "          [2464.],\n",
       "          [5370.],\n",
       "          [4473.],\n",
       "          [4950.],\n",
       "          [5003.],\n",
       "          [3260.],\n",
       "          [4074.],\n",
       "          [1325.],\n",
       "          [3189.],\n",
       "          [4538.],\n",
       "          [1878.],\n",
       "          [3460.],\n",
       "          [3859.],\n",
       "          [5433.],\n",
       "          [4489.],\n",
       "          [2551.],\n",
       "          [4838.],\n",
       "          [3601.],\n",
       "          [ 413.],\n",
       "          [4958.],\n",
       "          [4884.],\n",
       "          [ 530.],\n",
       "          [4772.],\n",
       "          [ 413.],\n",
       "          [5400.],\n",
       "          [3802.],\n",
       "          [5527.],\n",
       "          [ 360.],\n",
       "          [1414.],\n",
       "          [ 104.],\n",
       "          [5392.],\n",
       "          [3843.],\n",
       "          [4831.],\n",
       "          [2880.],\n",
       "          [ 104.],\n",
       "          [3310.],\n",
       "          [4412.],\n",
       "          [1774.],\n",
       "          [2905.],\n",
       "          [2239.],\n",
       "          [2262.],\n",
       "          [1325.],\n",
       "          [3129.],\n",
       "          [  31.],\n",
       "          [3189.],\n",
       "          [5331.],\n",
       "          [4538.],\n",
       "          [3741.],\n",
       "          [4860.],\n",
       "          [3906.],\n",
       "          [4950.],\n",
       "          [ 151.],\n",
       "          [3804.],\n",
       "          [ 615.],\n",
       "          [2461.],\n",
       "          [4743.],\n",
       "          [ 762.],\n",
       "          [ 385.],\n",
       "          [3841.],\n",
       "          [1963.],\n",
       "          [4928.],\n",
       "          [  88.],\n",
       "          [4950.],\n",
       "          [5553.],\n",
       "          [ 104.],\n",
       "          [1963.],\n",
       "          [5531.],\n",
       "          [5497.],\n",
       "          [4844.],\n",
       "          [5330.],\n",
       "          [4743.],\n",
       "          [ 921.],\n",
       "          [4838.],\n",
       "          [5448.],\n",
       "          [3996.],\n",
       "          [4950.],\n",
       "          [3431.],\n",
       "          [3335.],\n",
       "          [2290.],\n",
       "          [1341.],\n",
       "          [ 114.],\n",
       "          [5167.],\n",
       "          [4733.],\n",
       "          [4335.],\n",
       "          [1197.],\n",
       "          [1704.],\n",
       "          [2318.],\n",
       "          [3551.],\n",
       "          [5330.],\n",
       "          [4936.],\n",
       "          [4838.],\n",
       "          [1963.],\n",
       "          [2927.],\n",
       "          [ 151.],\n",
       "          [5723.],\n",
       "          [ 114.],\n",
       "          [ 163.],\n",
       "          [ 767.],\n",
       "          [1470.],\n",
       "          [3804.],\n",
       "          [ 701.],\n",
       "          [5003.],\n",
       "          [2058.],\n",
       "          [2240.],\n",
       "          [2461.],\n",
       "          [ 701.],\n",
       "          [3895.],\n",
       "          [2967.],\n",
       "          [ 685.],\n",
       "          [3512.],\n",
       "          [5231.],\n",
       "          [4489.],\n",
       "          [1977.],\n",
       "          [4743.],\n",
       "          [2452.],\n",
       "          [1501.],\n",
       "          [4950.],\n",
       "          [ 291.],\n",
       "          [3057.],\n",
       "          [3619.],\n",
       "          [5167.],\n",
       "          [ 587.],\n",
       "          [2262.],\n",
       "          [5242.],\n",
       "          [4760.],\n",
       "          [1326.],\n",
       "          [1701.],\n",
       "          [5330.],\n",
       "          [1897.],\n",
       "          [1933.],\n",
       "          [ 163.],\n",
       "          [4455.],\n",
       "          [4361.],\n",
       "          [4950.],\n",
       "          [4785.],\n",
       "          [5014.],\n",
       "          [5531.],\n",
       "          [1247.],\n",
       "          [1772.],\n",
       "          [4427.],\n",
       "          [1266.],\n",
       "          [3361.],\n",
       "          [2262.],\n",
       "          [4228.],\n",
       "          [ 504.],\n",
       "          [2643.],\n",
       "          [5098.],\n",
       "          [3804.],\n",
       "          [1182.],\n",
       "          [1325.],\n",
       "          [2135.],\n",
       "          [1871.],\n",
       "          [5553.],\n",
       "          [3906.],\n",
       "          [2498.],\n",
       "          [2112.],\n",
       "          [5700.],\n",
       "          [4950.],\n",
       "          [ 596.],\n",
       "          [ 819.],\n",
       "          [ 413.],\n",
       "          [ 413.],\n",
       "          [1655.],\n",
       "          [3796.],\n",
       "          [3692.],\n",
       "          [2514.],\n",
       "          [5360.],\n",
       "          [ 808.],\n",
       "          [2601.],\n",
       "          [3128.],\n",
       "          [4838.],\n",
       "          [4537.],\n",
       "          [4963.],\n",
       "          [ 228.],\n",
       "          [ 701.],\n",
       "          [1198.],\n",
       "          [2463.],\n",
       "          [ 654.],\n",
       "          [3697.],\n",
       "          [3877.],\n",
       "          [5448.],\n",
       "          [ 654.],\n",
       "          [2032.],\n",
       "          [1595.],\n",
       "          [4124.],\n",
       "          [5242.],\n",
       "          [ 688.],\n",
       "          [2421.],\n",
       "          [  57.],\n",
       "          [1560.],\n",
       "          [ 505.],\n",
       "          [1871.],\n",
       "          [  57.],\n",
       "          [5392.],\n",
       "          [4031.],\n",
       "          [2417.],\n",
       "          [3990.],\n",
       "          [ 163.],\n",
       "          [1254.],\n",
       "          [3033.],\n",
       "          [1897.],\n",
       "          [ 767.],\n",
       "          [2261.],\n",
       "          [ 217.],\n",
       "          [2615.]]),\n",
       "  tensor([[ 1.0957,  0.2570,  0.3757,  0.9661],\n",
       "          [-1.0545, -0.5545, -0.3572, -1.0832],\n",
       "          [ 1.0957, -1.3661,  1.1086,  0.9661],\n",
       "          ...,\n",
       "          [-2.4880, -0.5545, -1.0901, -1.7663],\n",
       "          [-3.2047, -2.9893, -3.2889, -2.4494],\n",
       "          [-1.0545,  0.2570,  0.3757, -0.4001]])],\n",
       " 'target': tensor([ 19,  17,  92,  31,  11,   3,   9,  46,  49,  12,  19, 102,   9, 103,\n",
       "          44,   4,  11,  65,  78,  17,   9,   2,  89,   9,  12,  12,  37,  21,\n",
       "          43,  12,  85,  92,  12,  65,  74,  37,  31,  86,  24,  26,   9,  73,\n",
       "          37,   7,  67,  18,   5,  61,  94,  16,  44,   2, 101,  94,  14,  26,\n",
       "         103,  14,   3,  18,  93,  93,  25,  65,  24, 102,  17,  20,  76,   9,\n",
       "          14,  14,  30,   2,  89,  12,   9,  93,  66,  84,  12,  94,  52,  14,\n",
       "          37,  37, 103,  17, 103,  37,   4,   2, 103,  26, 102,  38,  17,  14,\n",
       "           9,  92,  90,  82,  39,   9,  20,  49,  17,  16,  14,  78,  44,   9,\n",
       "          25,  11,   2,  47,  53,  60,  18,  15,   9,  41, 100,  83,  25,  98,\n",
       "          17,  29,  47,  86,   7, 102,   6,  52,  42,  17,  98,  93,   9,   9,\n",
       "           1,   9,   5,  37,  17,  26,   7,  65,  44,   4,  12,  42,  17,  61,\n",
       "          12,  82,  12,  19,  42,  39,  85,  55,  61,  12,  65,  12,  25,  11,\n",
       "          67,  14,  79,   2,  61,  49,  98,   9,  39,  12,  60,  78, 102,  49,\n",
       "          76,   2, 103,  12,   7,  60,  31,  53,  14, 103,  63,  44,  60,  10,\n",
       "          43,  83,  39,  89, 103,  19,  24,  14,  73,  12,  19,  38,  14,   9,\n",
       "          41,  12,  12,  93,   1, 103,  61,   9,  89,  46,  98,  92,  44,  23,\n",
       "          14, 103,  14, 102,  11,  12,  12,  60,  25,  48,  45,  58,   0,  12,\n",
       "          11,  89,  94,  44,  37,   9,  86,  14,   9,  42,   2,  95,  65,   2,\n",
       "           2,  39,  90,   9,  37,  59,  44,  15,  80,  34,  26,  12,  84,  17,\n",
       "          94,  98,  81,  60,  39, 103,  99,  16,  17,  61,  99,  16,  99,   4,\n",
       "          78,  39,  78,   2,  59,   7,  97,  60,  24,   1,  26,  50,  76,  98,\n",
       "           9,  11,  63,   1,  17,  89])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [tensor([[3791.],\n",
       "          [1341.],\n",
       "          [3799.],\n",
       "          [4473.],\n",
       "          [3747.],\n",
       "          [ 413.],\n",
       "          [3935.],\n",
       "          [ 384.],\n",
       "          [ 701.],\n",
       "          [2318.],\n",
       "          [ 291.],\n",
       "          [1282.],\n",
       "          [1450.],\n",
       "          [2239.],\n",
       "          [4794.],\n",
       "          [3033.],\n",
       "          [ 177.],\n",
       "          [1238.],\n",
       "          [5377.],\n",
       "          [ 151.],\n",
       "          [1342.],\n",
       "          [2262.],\n",
       "          [ 412.],\n",
       "          [5531.],\n",
       "          [5607.],\n",
       "          [ 413.],\n",
       "          [ 701.],\n",
       "          [2601.],\n",
       "          [2262.],\n",
       "          [4667.],\n",
       "          [5405.],\n",
       "          [  97.],\n",
       "          [1963.],\n",
       "          [ 154.],\n",
       "          [4963.],\n",
       "          [4843.],\n",
       "          [4950.],\n",
       "          [2880.],\n",
       "          [2884.],\n",
       "          [4843.],\n",
       "          [2262.],\n",
       "          [3841.],\n",
       "          [1032.],\n",
       "          [  57.],\n",
       "          [1282.],\n",
       "          [5078.],\n",
       "          [ 911.],\n",
       "          [3189.],\n",
       "          [4228.],\n",
       "          [ 173.],\n",
       "          [3014.],\n",
       "          [3802.],\n",
       "          [3608.],\n",
       "          [4950.],\n",
       "          [3547.],\n",
       "          [2464.],\n",
       "          [4094.],\n",
       "          [2967.],\n",
       "          [3872.],\n",
       "          [4598.],\n",
       "          [4762.],\n",
       "          [ 360.],\n",
       "          [2461.],\n",
       "          [4743.],\n",
       "          [3049.],\n",
       "          [ 277.],\n",
       "          [5167.],\n",
       "          [1326.],\n",
       "          [4473.],\n",
       "          [4010.],\n",
       "          [  94.],\n",
       "          [5132.],\n",
       "          [ 701.],\n",
       "          [ 163.],\n",
       "          [2484.],\n",
       "          [1963.],\n",
       "          [4950.],\n",
       "          [2262.],\n",
       "          [3595.],\n",
       "          [4228.],\n",
       "          [ 151.],\n",
       "          [3799.],\n",
       "          [3547.],\n",
       "          [1933.],\n",
       "          [4489.],\n",
       "          [5078.],\n",
       "          [5261.],\n",
       "          [1871.],\n",
       "          [5370.],\n",
       "          [1190.],\n",
       "          [3608.],\n",
       "          [2523.],\n",
       "          [1515.],\n",
       "          [ 375.],\n",
       "          [1335.],\n",
       "          [2523.],\n",
       "          [5507.],\n",
       "          [1776.],\n",
       "          [ 688.],\n",
       "          [ 701.],\n",
       "          [5078.],\n",
       "          [4598.],\n",
       "          [ 437.],\n",
       "          [ 831.],\n",
       "          [2461.],\n",
       "          [5448.],\n",
       "          [3431.],\n",
       "          [4361.],\n",
       "          [3396.],\n",
       "          [4843.],\n",
       "          [1453.],\n",
       "          [1299.],\n",
       "          [2207.],\n",
       "          [3512.],\n",
       "          [3189.],\n",
       "          [1325.],\n",
       "          [4990.],\n",
       "          [3297.],\n",
       "          [ 701.],\n",
       "          [  57.],\n",
       "          [1334.],\n",
       "          [3608.],\n",
       "          [1925.],\n",
       "          [4598.],\n",
       "          [4241.],\n",
       "          [5112.],\n",
       "          [1306.],\n",
       "          [ 413.],\n",
       "          [4489.],\n",
       "          [5562.],\n",
       "          [2498.],\n",
       "          [1558.],\n",
       "          [3438.],\n",
       "          [1719.],\n",
       "          [4642.],\n",
       "          [4762.],\n",
       "          [3478.],\n",
       "          [1963.],\n",
       "          [ 202.],\n",
       "          [ 235.],\n",
       "          [ 707.],\n",
       "          [ 235.],\n",
       "          [4228.],\n",
       "          [ 831.],\n",
       "          [3799.],\n",
       "          [2240.],\n",
       "          [5208.],\n",
       "          [2368.],\n",
       "          [3601.],\n",
       "          [1933.],\n",
       "          [3638.],\n",
       "          [4239.],\n",
       "          [5660.],\n",
       "          [2417.],\n",
       "          [ 770.],\n",
       "          [5003.],\n",
       "          [1085.],\n",
       "          [2781.],\n",
       "          [2551.],\n",
       "          [4743.],\n",
       "          [5448.],\n",
       "          [2239.],\n",
       "          [5182.],\n",
       "          [5553.],\n",
       "          [2464.],\n",
       "          [4538.],\n",
       "          [4880.],\n",
       "          [3805.],\n",
       "          [4617.],\n",
       "          [3638.],\n",
       "          [1719.],\n",
       "          [3548.],\n",
       "          [4412.],\n",
       "          [3841.],\n",
       "          [2909.],\n",
       "          [ 701.],\n",
       "          [ 819.],\n",
       "          [2769.],\n",
       "          [ 707.],\n",
       "          [ 375.],\n",
       "          [ 707.],\n",
       "          [ 505.],\n",
       "          [5448.],\n",
       "          [4473.],\n",
       "          [2544.],\n",
       "          [5128.],\n",
       "          [4412.],\n",
       "          [4624.],\n",
       "          [1776.],\n",
       "          [4743.],\n",
       "          [3896.],\n",
       "          [2417.],\n",
       "          [2797.],\n",
       "          [ 701.],\n",
       "          [4050.],\n",
       "          [3879.],\n",
       "          [3877.],\n",
       "          [ 375.],\n",
       "          [4950.],\n",
       "          [2927.],\n",
       "          [2207.],\n",
       "          [1933.],\n",
       "          [2698.],\n",
       "          [4743.],\n",
       "          [3260.],\n",
       "          [4538.],\n",
       "          [5293.],\n",
       "          [4794.],\n",
       "          [2909.],\n",
       "          [3083.],\n",
       "          [4743.],\n",
       "          [5278.],\n",
       "          [5208.],\n",
       "          [2262.],\n",
       "          [ 235.],\n",
       "          [3315.],\n",
       "          [ 701.],\n",
       "          [4884.],\n",
       "          [5553.],\n",
       "          [1963.],\n",
       "          [1507.],\n",
       "          [2262.],\n",
       "          [2417.],\n",
       "          [ 701.],\n",
       "          [2262.],\n",
       "          [ 104.],\n",
       "          [4950.],\n",
       "          [ 568.],\n",
       "          [5521.],\n",
       "          [ 701.],\n",
       "          [3189.],\n",
       "          [5370.],\n",
       "          [ 163.],\n",
       "          [4743.],\n",
       "          [3747.],\n",
       "          [2262.],\n",
       "          [4711.],\n",
       "          [5330.],\n",
       "          [ 596.],\n",
       "          [4228.],\n",
       "          [3802.],\n",
       "          [2909.],\n",
       "          [ 461.],\n",
       "          [2464.],\n",
       "          [4122.],\n",
       "          [1963.],\n",
       "          [1504.],\n",
       "          [ 235.],\n",
       "          [4743.],\n",
       "          [2207.],\n",
       "          [ 197.],\n",
       "          [ 375.],\n",
       "          [3608.],\n",
       "          [3799.],\n",
       "          [5078.],\n",
       "          [ 114.],\n",
       "          [ 831.],\n",
       "          [3804.],\n",
       "          [4538.],\n",
       "          [3991.],\n",
       "          [  10.],\n",
       "          [ 707.],\n",
       "          [4145.],\n",
       "          [2461.],\n",
       "          [5303.],\n",
       "          [3682.],\n",
       "          [2440.],\n",
       "          [2536.],\n",
       "          [2075.],\n",
       "          [3060.],\n",
       "          [1776.],\n",
       "          [2735.],\n",
       "          [ 104.],\n",
       "          [4950.],\n",
       "          [ 163.],\n",
       "          [1776.],\n",
       "          [2318.],\n",
       "          [5112.],\n",
       "          [4922.],\n",
       "          [2909.],\n",
       "          [2194.],\n",
       "          [1963.],\n",
       "          [ 916.],\n",
       "          [5308.],\n",
       "          [3805.],\n",
       "          [1335.],\n",
       "          [ 326.],\n",
       "          [1933.],\n",
       "          [1897.],\n",
       "          [1936.],\n",
       "          [2262.],\n",
       "          [5725.],\n",
       "          [1963.],\n",
       "          [5448.],\n",
       "          [1195.],\n",
       "          [3079.],\n",
       "          [1275.],\n",
       "          [1448.],\n",
       "          [4743.],\n",
       "          [4950.]]),\n",
       "  tensor([[-1.0545,  0.2570, -0.3572, -1.0832],\n",
       "          [ 0.3790,  1.0686, -2.5560,  0.9661],\n",
       "          [ 0.3790,  1.0686, -0.3572,  0.9661],\n",
       "          ...,\n",
       "          [-1.7712, -2.9893, -1.8230, -0.4001],\n",
       "          [ 0.3790,  1.0686,  0.3757,  0.2830],\n",
       "          [ 1.0957,  1.8802,  1.1086,  0.9661]])],\n",
       " 'target': tensor([ 44,  39,  12,  81,  47,  18,  67,  14,  82,  49,  14,  23,  14,   9,\n",
       "          84,  12,   9,  85,   2,  33,  39,  89,   1,  83,  96,   9,  76,  12,\n",
       "           9, 100,   9,  11,  74,  12,  61,  82,  23,  47,  92,  81,  11,  84,\n",
       "          37,   7,  23,  11,  24, 100,   9,  68,  35,  61,  12,   7,  89,  46,\n",
       "          37,  85,  44,  89,  90,  71,  26,  12,  36,  47,  86,  21,  12,  59,\n",
       "           6,  19,  60,   1,  47,  18,  89,  94, 103,   9, 102,  14,  46,  42,\n",
       "           4,  11,  61,  89,   7,  18,  12,  67,  47,  11,  23,  59,  14,  76,\n",
       "          12,  12,  79,  49,  94,  26,  92,   4,  60,  81,  81,  37,  82,  25,\n",
       "           9,  18,  92,  98,  47,  16,  16,  39,  26,  12,  18,  44,  14,  98,\n",
       "          74,  11,   6,  79,  55,   4,  31,  23,  60,  61,   1,  10,   1,  84,\n",
       "         102,  12,   9,  92,   6,  59,  12,  35,  25,  14,  12,  12,  55,  59,\n",
       "          29,  12,  37,   9,  12,   9,  98,  14,  30,  42, 103,  12,  61,  85,\n",
       "          83,  14,  23,  49,  55,  26, 101,  60,  12,  42,  17,  90,  16,  17,\n",
       "          61,  18,  19,  47,  12,  69, 103,  86,  44,  24,  17,  93,  17,  43,\n",
       "           6,  27,  11,  89,  19,  12,  17,  19,  89,  20,  25,  12,  44,  80,\n",
       "          19,   7,   0,  12,  92,   2,  37,  51,  12,  85,  16,  11,  11, 103,\n",
       "          90,  98,  79,  42, 100, 103,   9,  17,  76,   9,  65,  60,  17,  44,\n",
       "          25,   9,  19,  14, 103,  19,  73,  25,  20,   9,  12,  42,  69,   2,\n",
       "          11,  22,  14,   4,  92,  27,   9,  82,  14,  82,   1,   4,  94,   2,\n",
       "          14,  89,  60,  65,  39,  42,  98,   9,  17,  76,  55,  26,  53,  20,\n",
       "          15,  18,  86,  49,  37,  57,  65,  18,  89,   1,  12,  97,  25,  12,\n",
       "          36,  37,  86,  36,  12,  89])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [tensor([[4884.],\n",
       "          [ 163.],\n",
       "          [ 217.],\n",
       "          [ 163.],\n",
       "          [2262.],\n",
       "          [5378.],\n",
       "          [4280.],\n",
       "          [ 413.],\n",
       "          [5003.],\n",
       "          [2461.],\n",
       "          [2461.],\n",
       "          [2316.],\n",
       "          [3841.],\n",
       "          [5066.],\n",
       "          [4453.],\n",
       "          [2461.],\n",
       "          [3341.],\n",
       "          [ 151.],\n",
       "          [4830.],\n",
       "          [2239.],\n",
       "          [5014.],\n",
       "          [3237.],\n",
       "          [2514.],\n",
       "          [5378.],\n",
       "          [5014.],\n",
       "          [5448.],\n",
       "          [3189.],\n",
       "          [5242.],\n",
       "          [2523.],\n",
       "          [1605.],\n",
       "          [2601.],\n",
       "          [5364.],\n",
       "          [ 163.],\n",
       "          [5078.],\n",
       "          [ 224.],\n",
       "          [2689.],\n",
       "          [4132.],\n",
       "          [ 375.],\n",
       "          [ 360.],\n",
       "          [3888.],\n",
       "          [2239.],\n",
       "          [5392.],\n",
       "          [1334.],\n",
       "          [4598.],\n",
       "          [1951.],\n",
       "          [4680.],\n",
       "          [1306.],\n",
       "          [5330.],\n",
       "          [ 154.],\n",
       "          [3804.],\n",
       "          [4950.],\n",
       "          [ 386.],\n",
       "          [2927.],\n",
       "          [4794.],\n",
       "          [4228.],\n",
       "          [1776.],\n",
       "          [3843.],\n",
       "          [ 291.],\n",
       "          [2909.],\n",
       "          [1871.],\n",
       "          [4228.],\n",
       "          [2239.],\n",
       "          [3431.],\n",
       "          [ 509.],\n",
       "          [2262.],\n",
       "          [4453.],\n",
       "          [1168.],\n",
       "          [5370.],\n",
       "          [3057.],\n",
       "          [4538.],\n",
       "          [2989.],\n",
       "          [ 701.],\n",
       "          [3526.],\n",
       "          [ 587.],\n",
       "          [5726.],\n",
       "          [ 235.],\n",
       "          [1506.],\n",
       "          [1933.],\n",
       "          [4077.],\n",
       "          [4262.],\n",
       "          [4794.],\n",
       "          [ 615.],\n",
       "          [ 413.],\n",
       "          [ 177.],\n",
       "          [4743.],\n",
       "          [ 235.],\n",
       "          [2698.],\n",
       "          [4950.],\n",
       "          [2262.],\n",
       "          [2270.],\n",
       "          [2523.],\n",
       "          [3194.],\n",
       "          [4280.],\n",
       "          [3799.],\n",
       "          [4963.],\n",
       "          [3804.],\n",
       "          [3341.],\n",
       "          [5253.],\n",
       "          [1933.],\n",
       "          [ 911.],\n",
       "          [5003.],\n",
       "          [1338.],\n",
       "          [1285.],\n",
       "          [3099.],\n",
       "          [1899.],\n",
       "          [4832.],\n",
       "          [4031.],\n",
       "          [5448.],\n",
       "          [2927.],\n",
       "          [ 836.],\n",
       "          [4863.],\n",
       "          [3841.],\n",
       "          [ 829.],\n",
       "          [5242.],\n",
       "          [1306.],\n",
       "          [5448.],\n",
       "          [5112.],\n",
       "          [1776.],\n",
       "          [2642.],\n",
       "          [1303.],\n",
       "          [4950.],\n",
       "          [4280.],\n",
       "          [4611.],\n",
       "          [2967.],\n",
       "          [2262.],\n",
       "          [ 767.],\n",
       "          [3208.],\n",
       "          [4843.],\n",
       "          [ 154.],\n",
       "          [4357.],\n",
       "          [1314.],\n",
       "          [2927.],\n",
       "          [4226.],\n",
       "          [4748.],\n",
       "          [3809.],\n",
       "          [  48.],\n",
       "          [1325.],\n",
       "          [ 151.],\n",
       "          [1895.],\n",
       "          [ 413.],\n",
       "          [5112.],\n",
       "          [4794.],\n",
       "          [4412.],\n",
       "          [1515.],\n",
       "          [1719.],\n",
       "          [5278.],\n",
       "          [4537.],\n",
       "          [4141.],\n",
       "          [ 596.],\n",
       "          [4540.],\n",
       "          [2112.],\n",
       "          [4241.],\n",
       "          [3996.],\n",
       "          [4619.],\n",
       "          [2601.],\n",
       "          [5582.],\n",
       "          [1936.],\n",
       "          [3799.],\n",
       "          [5527.],\n",
       "          [3596.],\n",
       "          [4485.],\n",
       "          [2523.],\n",
       "          [ 104.],\n",
       "          [1558.],\n",
       "          [2412.],\n",
       "          [ 598.],\n",
       "          [2262.],\n",
       "          [ 235.],\n",
       "          [ 151.],\n",
       "          [4682.],\n",
       "          [4794.],\n",
       "          [ 440.],\n",
       "          [3788.],\n",
       "          [2512.],\n",
       "          [ 716.],\n",
       "          [ 411.],\n",
       "          [2262.],\n",
       "          [1238.],\n",
       "          [1168.],\n",
       "          [3608.],\n",
       "          [4624.],\n",
       "          [5332.],\n",
       "          [4384.],\n",
       "          [ 697.],\n",
       "          [1933.],\n",
       "          [4863.],\n",
       "          [ 151.],\n",
       "          [ 911.],\n",
       "          [4743.],\n",
       "          [2262.],\n",
       "          [ 831.],\n",
       "          [1325.],\n",
       "          [4748.],\n",
       "          [4241.],\n",
       "          [4489.],\n",
       "          [2318.],\n",
       "          [4353.],\n",
       "          [4447.],\n",
       "          [2464.],\n",
       "          [3804.],\n",
       "          [2417.],\n",
       "          [1473.],\n",
       "          [4863.],\n",
       "          [2523.],\n",
       "          [  57.],\n",
       "          [5448.],\n",
       "          [2464.],\n",
       "          [4950.],\n",
       "          [5242.],\n",
       "          [5003.],\n",
       "          [4733.],\n",
       "          [5563.],\n",
       "          [5392.],\n",
       "          [5485.],\n",
       "          [4838.],\n",
       "          [2967.],\n",
       "          [3512.],\n",
       "          [1776.],\n",
       "          [4794.],\n",
       "          [1198.],\n",
       "          [1198.],\n",
       "          [4031.],\n",
       "          [2529.],\n",
       "          [3596.],\n",
       "          [3189.],\n",
       "          [2537.],\n",
       "          [ 151.],\n",
       "          [2601.],\n",
       "          [ 413.],\n",
       "          [4489.],\n",
       "          [1728.],\n",
       "          [2536.],\n",
       "          [1414.],\n",
       "          [2262.],\n",
       "          [5278.],\n",
       "          [ 413.],\n",
       "          [5003.],\n",
       "          [4972.],\n",
       "          [1318.],\n",
       "          [1963.],\n",
       "          [2668.],\n",
       "          [3804.],\n",
       "          [3872.],\n",
       "          [4838.],\n",
       "          [ 163.],\n",
       "          [4963.],\n",
       "          [5392.],\n",
       "          [2464.],\n",
       "          [ 151.],\n",
       "          [ 701.],\n",
       "          [1314.],\n",
       "          [4863.],\n",
       "          [ 670.],\n",
       "          [1342.],\n",
       "          [5737.],\n",
       "          [3906.],\n",
       "          [5553.],\n",
       "          [4489.],\n",
       "          [4489.],\n",
       "          [ 413.],\n",
       "          [ 163.],\n",
       "          [ 363.],\n",
       "          [3847.],\n",
       "          [5527.],\n",
       "          [4950.],\n",
       "          [1933.],\n",
       "          [5529.],\n",
       "          [3677.],\n",
       "          [3624.],\n",
       "          [1198.],\n",
       "          [1330.],\n",
       "          [1334.],\n",
       "          [3853.],\n",
       "          [ 515.],\n",
       "          [5132.],\n",
       "          [ 704.],\n",
       "          [4838.],\n",
       "          [4838.],\n",
       "          [3294.],\n",
       "          [4489.],\n",
       "          [  97.],\n",
       "          [1198.],\n",
       "          [ 701.],\n",
       "          [3189.],\n",
       "          [4950.],\n",
       "          [4939.],\n",
       "          [3128.],\n",
       "          [3692.],\n",
       "          [4743.],\n",
       "          [ 767.],\n",
       "          [2262.],\n",
       "          [ 701.],\n",
       "          [5115.],\n",
       "          [ 596.],\n",
       "          [4729.],\n",
       "          [ 819.],\n",
       "          [5364.],\n",
       "          [ 707.],\n",
       "          [2461.],\n",
       "          [1238.]]),\n",
       "  tensor([[ 0.3790,  0.2570,  0.3757,  0.2830],\n",
       "          [-1.0545, -0.5545, -1.0901, -1.0832],\n",
       "          [-0.3378,  0.2570, -0.3572,  0.2830],\n",
       "          ...,\n",
       "          [-0.3378,  1.0686, -1.8230, -1.0832],\n",
       "          [ 0.3790,  1.0686,  1.1086,  0.9661],\n",
       "          [-0.3378,  0.2570,  0.3757, -0.4001]])],\n",
       " 'target': tensor([ 79,  31,  80,  15,  84,   0,  65,  11,  79,  23,  89,  93,  61,  27,\n",
       "          53,  84,  65,  33,  14, 103,  86,  44,  80,   0,  12,   9,  19,  14,\n",
       "          68,   1,  16,  98,  77,  14,   3,  18,  84,  12,  81,  44,  17,  98,\n",
       "          26,  46,  82,  17,  74,  17,  16,  20,   2,  66,   3,  14,   9,  76,\n",
       "          14,   2,  44,  60,  89,  21,  60,  12,  11,  31,   7,  17,  15,  24,\n",
       "          65,  31,   2,  61,  36,   4,  79,  14,   1,  92,  86,  47,  14,   2,\n",
       "          14,  67,  16,  17,  90,  83,  67,  35,  37,  24,  17,  60,  65,  32,\n",
       "          42,  24,  12,  58,  26,  17,   7,   6,  13, 103,  60,  92,  67,  26,\n",
       "          25,   9,  74,  12,  66,  16,  42,  26,  17,  37,  18,  29,  94,  74,\n",
       "          37,  37,  16,  61,  63,  60,  36,  55,  45,  24,  39,  31,  58,  16,\n",
       "          25,  17,  36,  47,  23,  37,  94,   6,  98,  12,  65,  12,   9,  20,\n",
       "           9,  16,   1,  16,  65,  51,  16,  68,  39,  14,  11,  14,  90,  86,\n",
       "         102, 102,  99,  61,   2,  52,  18,  94,  94,  89,  17,  70,  69,  49,\n",
       "          55,  14,   9,   1, 102,  24,  86,  94,  92,  39,  94,  98,  66,  49,\n",
       "           5,  90,  17,  40,  17,  89,  78,  77,  76,  12,  68,  19,  89,  43,\n",
       "          12,  26,  98,  90,  19,  25,  68,  76,  94,  22,  39,   1,  47,  51,\n",
       "           2,  81, 102,  16, 103,   7,  82,  89,  60,  11,  37,  19,  43,   1,\n",
       "          58,  25,   9,  60,   4,  12,  76,  42,  25,  31,  17,   4,  63,  37,\n",
       "          36,  24,  37,  20,   9,  60,  16,  89,   3,  12,   5,  65,   5,  18,\n",
       "          89,  14,  59,  29,  75,  86,   9,  77,  42,  89,  19,   2,  84,  83,\n",
       "           9,  39,  82,  16,  14,  16,  84,   1,  12,  74,   9,  60,  44,  25,\n",
       "          66,  11,   0,   9,  89,  90])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.sampler.SequentialSampler object at 0x7f0b39d4e450>\n"
     ]
    }
   ],
   "source": [
    "print(valid_loader.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader, valid_loader,\n",
    "                  loss_func, optimizer, n_epochs=20,\n",
    "                  saved_model='model.pt'):\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses = list()\n",
    "    valid_losses = list()\n",
    "    \n",
    "    valid_loss_min = np.Inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long),\n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float))\n",
    "            \n",
    "            loss = loss_func(output, batch['target'].to(device, \n",
    "                                                        dtype=torch.long))\n",
    "            \n",
    "            train_loss += loss.item() * batch['data'][0].size(0)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate global accuracy\n",
    "            train_acc += (output.argmax(1) == batch['target']).sum().item()\n",
    "\n",
    "            \n",
    "    \n",
    "\n",
    "        model.eval()\n",
    "        for batch in tqdm(valid_loader):\n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long),\n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float))\n",
    "            \n",
    "            \n",
    "            loss = loss_func(output, batch['target'].to(device, \n",
    "                                                        dtype=torch.long))\n",
    "            \n",
    "            valid_loss += loss.item() * batch['data'][0].size(0)  #!!!\n",
    "            # Calculate global accuracy\n",
    "            valid_acc += (output.argmax(1) == batch['target']).sum().item()\n",
    "        \n",
    "        train_loss = np.sqrt(train_loss / len(train_loader))\n",
    "        valid_loss = np.sqrt(valid_loss / len(valid_loader))\n",
    "\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        valid_acc = valid_acc / len(valid_loader)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print('Epoch: {}. Training loss: {:.8f}. Validation loss: {:.8f}'\n",
    "              .format(epoch, train_loss, valid_loss))\n",
    "        print('Training Accuracy: {:.8f}. Validation Accuracy: {:.8f}'\n",
    "              .format(train_acc, valid_acc))\n",
    "        \n",
    "        if valid_loss < valid_loss_min:  # let's save the best weights to use them in prediction\n",
    "            print('Validation loss decreased ({:.8f} --> {:.8f}). Saving model...'\n",
    "                  .format(valid_loss_min, valid_loss))\n",
    "            \n",
    "            torch.save(model.state_dict(), saved_model)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3c95a34aef4d698b09c88dbb38da78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f71c3400eb442b698b2525410e32a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0. Training loss: 37.07604849. Validation loss: 37.09084730\n",
      "Training Accuracy: 23.24417139. Validation Accuracy: 22.14744802\n",
      "Validation loss decreased (inf --> 37.09084730). Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933c0988553748198c032d394c792181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf0b344c6394e2da35dc055dc920961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1. Training loss: 37.10066659. Validation loss: 37.09084730\n",
      "Training Accuracy: 21.41682420. Validation Accuracy: 22.14744802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce4ce7c43774a798f26e86e8a1e9ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ea42953f2a439292de29a14a64d8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2. Training loss: 37.08895869. Validation loss: 37.09084730\n",
      "Training Accuracy: 22.28607435. Validation Accuracy: 22.14744802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a228545bb34f4d47867b9474170d498e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8dd850b805041c28b2501c84363e37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3. Training loss: 37.08897145. Validation loss: 37.09084730\n",
      "Training Accuracy: 22.28512917. Validation Accuracy: 22.14744802\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b12cf8c115f4f8ca8fca4facc2dc81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb97d71944d4f23a7b811f664ad90db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4. Training loss: 37.08890339. Validation loss: 37.09084730\n",
      "Training Accuracy: 22.29017013. Validation Accuracy: 22.14744802\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = train_network(model=model, \n",
    "                                           train_loader=train_loader, \n",
    "                                           valid_loader=valid_loader, \n",
    "                                           loss_func=criterion, \n",
    "                                           optimizer=optimizer,\n",
    "                                           n_epochs=5, \n",
    "                                           saved_model='../models/embed_3layers.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.076048493787276,\n",
       " 37.10066659011123,\n",
       " 37.088958694775506,\n",
       " 37.088971449476695,\n",
       " 37.08890338526]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa13c6ded0f34c7ab7fb58c7b6a614a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:45: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ec45c27c344fdcbcd7aaa0839d124c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n",
      "Validation loss decreased (inf --> 37.090847). Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3222e498408c4eff8a1791a83509591d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc39604deb98484daba3f239fafa1f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ce3e78525b47d585eb6e2a4bab8980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0b2e3c9fe44185b71d894310150981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1c7c99f5ce406aadcea582f36c34d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0cfada71042446f969f3f3c165fbb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca70e1b07ed49dd969e386d53713bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130e95573dd8493993761837cac9d012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316281a960014f65a7f88f167e2a43e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6363e1b080f340f58b19d4e8a9adfc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b7a28665e64e42986637c66453efd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c8f880076541159c14d8e68c3af920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04fde003e8a4f938a74e67e3a98f46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b431f466fb4acba684d3bd9ba3b488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07a231d36914920ae16a8834a1c15fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7905388c8881436ab8658bc925f18139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66019cb32264e5381d0ff324d12d129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff31b9b2e30470cadcaa62613d37fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a7c14c02f74e4db93dd26e3b450b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aaf25889e40461aa95948787b3ef675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 10. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915ea27af1d14588a1fa7bd1d0345b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30592f6cd53946b98190d743bd81b6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 11. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d54a604e3f4388ba00113ab315a10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3e67a6ab8e4b72b2e326c2c88a4563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 12. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac122343803402fb83768769b117cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee744afc47234d299cd5c26d27142cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 13. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62902414f7046a1a3059e9fbc526a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae91e3a0236451389b11fb04cf68c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 14. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f775b3438e4b7c9922d8b1cbbbbc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd2fc594d894a67840a5c35a98fad80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 15. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6366389017cc4419b2fb35ade1986e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd9dd5069c04acfad45bcf11e672423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 16. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26b88fef11843f095ff33e1f447fcd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fcc5e40e5e45c98bd89d2ddbe06719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 17. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e561412485c6480994519e850bcda855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6380f6a825694b00ae3af4fa208cc6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 18. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e60a960b3984b8298c62a690081abbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb2ba16067e41969a21dd03764b4314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 19. Training loss: 37.088971. Validation loss: 37.090847\n",
      "Training Accuracy: 22.285129. Validation Accuracy: 22.147448\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = train_network(model=model, \n",
    "                                           train_loader=train_loader, \n",
    "                                           valid_loader=valid_loader, \n",
    "                                           loss_func=criterion, \n",
    "                                           optimizer=optimizer,\n",
    "                                           n_epochs=20, \n",
    "                                           saved_model='../models/embed_3layers3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.08897145257539,\n",
       " 37.08897144565699,\n",
       " 37.088971451848316,\n",
       " 37.08897145833736,\n",
       " 37.08897145653485,\n",
       " 37.08897143048752,\n",
       " 37.088971442420565,\n",
       " 37.088971460239115,\n",
       " 37.088971455319665,\n",
       " 37.088971462784905,\n",
       " 37.088971445598254,\n",
       " 37.088971451360216,\n",
       " 37.08897147399492,\n",
       " 37.088971460648224,\n",
       " 37.088971445871664,\n",
       " 37.08897143452191,\n",
       " 37.088971458825455,\n",
       " 37.08897144973188,\n",
       " 37.088971462491244,\n",
       " 37.088971465529184]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025,\n",
       " 37.090847304752025]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_loader.sampler.indices doesn't work\n",
    "\n",
    "Therefore need to divide by the batch size manually, or find alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 37.089%\n",
      "Validation loss: 37.091%\n"
     ]
    }
   ],
   "source": [
    "print('Training loss: {:.3f}%'.format(np.mean(train_losses)))\n",
    "print('Validation loss: {:.3f}%'.format(np.mean(valid_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = None\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(data_loader)):   \n",
    "            \n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long), \n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float)).cpu().numpy()\n",
    "            \n",
    "            if i == 0:\n",
    "                predictions = output\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                predictions = np.vstack((predictions, output))\n",
    "                \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e593c555f74209a556bc67cea56299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/embed_3layers.pt'))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE)\n",
    "\n",
    "nn_predictions = predict(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 12, 12, ..., 12, 12, 12])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold = 100)\n",
    "nn_predictions.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (nn_predictions.argmax(1) == y_test).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07380247069204589"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc/317320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     8      9     53 ... 317281 317303 317313]\n"
     ]
    }
   ],
   "source": [
    "twelves = np.where(y_test == 12)\n",
    "print(sum(list(twelves)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute other metrics\n",
    "roc_auc_score(y_test,nn_predictions, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83 102  11 ...  43   9  14]\n",
      "[12 12 12 ... 12 12 12]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(nn_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cr_to_dataframe(report_dict:dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the dictionary format of the Classification Report (CR) to a\n",
    "    dataframe for easy of sorting\n",
    "    :param report_dict: The dictionary returned by \n",
    "    sklearn.metrics.classification_report.\n",
    "    :return: Returns a dataframe of the same information.\n",
    "    \"\"\"\n",
    "    beer_style = list(report_dict.keys())\n",
    "    beer_style.remove('accuracy')\n",
    "    beer_style.remove('macro avg')\n",
    "    beer_style.remove('weighted avg')\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    support = []\n",
    "    for key, value in report_dict.items():\n",
    "        if key not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "            precision.append(value['precision'])\n",
    "            recall.append(value['recall'])\n",
    "            f1.append(value['f1-score'])\n",
    "            support.append(value['support'])\n",
    "    result = pd.DataFrame({'beer_style': beer_style,\n",
    "                           'precision': precision,\n",
    "                           'recall': recall,\n",
    "                           'f1': f1,\n",
    "                           'support': support})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "style_encoder = load('../models/style_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              beer_style  precision  recall       f1  support\n",
      "0                                Altbier   0.000000     0.0  0.00000     1574\n",
      "1                 American Adjunct Lager   0.000000     0.0  0.00000     6047\n",
      "2               American Amber / Red Ale   0.000000     0.0  0.00000     9298\n",
      "3             American Amber / Red Lager   0.000000     0.0  0.00000     1851\n",
      "4                    American Barleywine   0.000000     0.0  0.00000     5439\n",
      "5                     American Black Ale   0.000000     0.0  0.00000     2336\n",
      "6                    American Blonde Ale   0.000000     0.0  0.00000     2579\n",
      "7                     American Brown Ale   0.000000     0.0  0.00000     5026\n",
      "8                American Dark Wheat Ale   0.000000     0.0  0.00000      284\n",
      "9         American Double / Imperial IPA   0.000000     0.0  0.00000    17309\n",
      "10    American Double / Imperial Pilsner   0.000000     0.0  0.00000     1150\n",
      "11      American Double / Imperial Stout   0.000000     0.0  0.00000    10117\n",
      "12                          American IPA   0.073802     1.0  0.13746    23419\n",
      "13                  American Malt Liquor   0.000000     0.0  0.00000      763\n",
      "14               American Pale Ale (APA)   0.000000     0.0  0.00000    12617\n",
      "15                   American Pale Lager   0.000000     0.0  0.00000     1777\n",
      "16               American Pale Wheat Ale   0.000000     0.0  0.00000     4979\n",
      "17                       American Porter   0.000000     0.0  0.00000    10009\n",
      "18                        American Stout   0.000000     0.0  0.00000     4930\n",
      "19                   American Strong Ale   0.000000     0.0  0.00000     6375\n",
      "20                     American Wild Ale   0.000000     0.0  0.00000     3495\n",
      "21                         Baltic Porter   0.000000     0.0  0.00000     2362\n",
      "22                      Belgian Dark Ale   0.000000     0.0  0.00000     1277\n",
      "23                           Belgian IPA   0.000000     0.0  0.00000     2419\n",
      "24                      Belgian Pale Ale   0.000000     0.0  0.00000     3932\n",
      "25               Belgian Strong Dark Ale   0.000000     0.0  0.00000     7576\n",
      "26               Belgian Strong Pale Ale   0.000000     0.0  0.00000     6203\n",
      "27                    Berliner Weissbier   0.000000     0.0  0.00000      709\n",
      "28       Bire de Champagne / Bire Brut   0.000000     0.0  0.00000      224\n",
      "29                        Bire de Garde   0.000000     0.0  0.00000     1330\n",
      "30                           Black & Tan   0.000000     0.0  0.00000      487\n",
      "31                                  Bock   0.000000     0.0  0.00000     2315\n",
      "32                               Braggot   0.000000     0.0  0.00000      218\n",
      "33        California Common / Steam Beer   0.000000     0.0  0.00000      807\n",
      "34                            Chile Beer   0.000000     0.0  0.00000      460\n",
      "35                             Cream Ale   0.000000     0.0  0.00000     1017\n",
      "36                        Czech Pilsener   0.000000     0.0  0.00000     2557\n",
      "37                            Doppelbock   0.000000     0.0  0.00000     4391\n",
      "38             Dortmunder / Export Lager   0.000000     0.0  0.00000      971\n",
      "39                                Dubbel   0.000000     0.0  0.00000     4048\n",
      "40                          Dunkelweizen   0.000000     0.0  0.00000     1411\n",
      "41                               Eisbock   0.000000     0.0  0.00000      553\n",
      "42                    English Barleywine   0.000000     0.0  0.00000     2730\n",
      "43                        English Bitter   0.000000     0.0  0.00000     1743\n",
      "44                     English Brown Ale   0.000000     0.0  0.00000     3903\n",
      "45                 English Dark Mild Ale   0.000000     0.0  0.00000      499\n",
      "46          English India Pale Ale (IPA)   0.000000     0.0  0.00000     3206\n",
      "47                      English Pale Ale   0.000000     0.0  0.00000     4680\n",
      "48                 English Pale Mild Ale   0.000000     0.0  0.00000      134\n",
      "49                        English Porter   0.000000     0.0  0.00000     2269\n",
      "50                         English Stout   0.000000     0.0  0.00000      614\n",
      "51                    English Strong Ale   0.000000     0.0  0.00000      983\n",
      "52                       Euro Dark Lager   0.000000     0.0  0.00000      893\n",
      "53                       Euro Pale Lager   0.000000     0.0  0.00000     3688\n",
      "54                     Euro Strong Lager   0.000000     0.0  0.00000      543\n",
      "55   Extra Special / Strong Bitter (ESB)   0.000000     0.0  0.00000     3476\n",
      "56                                  Faro   0.000000     0.0  0.00000      102\n",
      "57                    Flanders Oud Bruin   0.000000     0.0  0.00000      959\n",
      "58                      Flanders Red Ale   0.000000     0.0  0.00000     1307\n",
      "59                Foreign / Export Stout   0.000000     0.0  0.00000     1145\n",
      "60                Fruit / Vegetable Beer   0.000000     0.0  0.00000     6713\n",
      "61                       German Pilsener   0.000000     0.0  0.00000     4333\n",
      "62                                  Gose   0.000000     0.0  0.00000      129\n",
      "63                                Gueuze   0.000000     0.0  0.00000     1195\n",
      "64                              Happoshu   0.000000     0.0  0.00000       50\n",
      "65                            Hefeweizen   0.000000     0.0  0.00000     5572\n",
      "66                  Herbed / Spiced Beer   0.000000     0.0  0.00000     2071\n",
      "67                       Irish Dry Stout   0.000000     0.0  0.00000     2507\n",
      "68                         Irish Red Ale   0.000000     0.0  0.00000     1546\n",
      "69                   Japanese Rice Lager   0.000000     0.0  0.00000      290\n",
      "70            Keller Bier / Zwickel Bier   0.000000     0.0  0.00000      514\n",
      "71                         Kristalweizen   0.000000     0.0  0.00000      459\n",
      "72                                 Kvass   0.000000     0.0  0.00000       70\n",
      "73                                Klsch   0.000000     0.0  0.00000     1686\n",
      "74                        Lambic - Fruit   0.000000     0.0  0.00000     2122\n",
      "75                    Lambic - Unblended   0.000000     0.0  0.00000      220\n",
      "76                           Light Lager   0.000000     0.0  0.00000     2794\n",
      "77                      Low Alcohol Beer   0.000000     0.0  0.00000      228\n",
      "78                 Maibock / Helles Bock   0.000000     0.0  0.00000     2104\n",
      "79                    Milk / Sweet Stout   0.000000     0.0  0.00000     2638\n",
      "80                   Munich Dunkel Lager   0.000000     0.0  0.00000     1581\n",
      "81                   Munich Helles Lager   0.000000     0.0  0.00000     1599\n",
      "82                  Mrzen / Oktoberfest   0.000000     0.0  0.00000     4706\n",
      "83                         Oatmeal Stout   0.000000     0.0  0.00000     3600\n",
      "84                               Old Ale   0.000000     0.0  0.00000     2998\n",
      "85                           Pumpkin Ale   0.000000     0.0  0.00000     3019\n",
      "86                      Quadrupel (Quad)   0.000000     0.0  0.00000     3716\n",
      "87                             Rauchbier   0.000000     0.0  0.00000      804\n",
      "88                            Roggenbier   0.000000     0.0  0.00000      109\n",
      "89                Russian Imperial Stout   0.000000     0.0  0.00000    10734\n",
      "90                              Rye Beer   0.000000     0.0  0.00000     2057\n",
      "91                                 Sahti   0.000000     0.0  0.00000      208\n",
      "92                Saison / Farmhouse Ale   0.000000     0.0  0.00000     6320\n",
      "93                           Schwarzbier   0.000000     0.0  0.00000     1936\n",
      "94                Scotch Ale / Wee Heavy   0.000000     0.0  0.00000     3479\n",
      "95                          Scottish Ale   0.000000     0.0  0.00000     1825\n",
      "96   Scottish Gruit / Ancient Herbed Ale   0.000000     0.0  0.00000      558\n",
      "97                           Smoked Beer   0.000000     0.0  0.00000      595\n",
      "98                                Tripel   0.000000     0.0  0.00000     6063\n",
      "99                          Vienna Lager   0.000000     0.0  0.00000     1825\n",
      "100                           Weizenbock   0.000000     0.0  0.00000     1900\n",
      "101                            Wheatwine   0.000000     0.0  0.00000      769\n",
      "102                        Winter Warmer   0.000000     0.0  0.00000     4140\n",
      "103                              Witbier   0.000000     0.0  0.00000     6023\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 150\n",
    "report_dict = classification_report(style_encoder.inverse_transform(y_test),\n",
    "                                    style_encoder.inverse_transform(nn_predictions.argmax(1)),\n",
    "                                    output_dict=True)\n",
    "report_df = convert_cr_to_dataframe(report_dict)\n",
    "print(report_df)\n",
    "#classification_report(y_test, nn_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv('../data/processed/class_report_badmodel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, \"../models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "epochs = range(1,5)\n",
    "plt.plot(train_losses, 'g', label='Training loss')\n",
    "plt.plot(valid_losses, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.076048493787276,\n",
       " 37.10066659011123,\n",
       " 37.088958694775506,\n",
       " 37.088971449476695,\n",
       " 37.08890338526]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_encoder = load('../models/name_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [\"'t Hofbrouwerijke\" '(512) Brewing Company' '10 Barrel Brewing Co.' ...\n 'lfabrikken' 'rbk Bryggeri' 'dzkie Browary S.A.']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-147b3db98719>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mle_name_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mle_name_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             raise ValueError(\n\u001b[0;32m--> 297\u001b[0;31m                     \"y contains previously unseen labels: %s\" % str(diff))\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: [\"'t Hofbrouwerijke\" '(512) Brewing Company' '10 Barrel Brewing Co.' ...\n 'lfabrikken' 'rbk Bryggeri' 'dzkie Browary S.A.']"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(name_encoder.classes_, name_encoder.inverse_transform(name_encoder.classes_)))\n",
    "print(pd.DataFrame.from_dict(le_name_mapping, orient='index',columns=['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
