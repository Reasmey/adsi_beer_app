{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "https://www.kaggle.com/vadbeg/pytorch-nn-with-embeddings-and-catboost/notebook#PyTorch\n",
    "\n",
    "mostly based off this example, plus parts of code form tutorial 5 lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import load_data function from \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# fix system path\n",
    "import sys\n",
    "sys.path.append(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministick = True\n",
    "    torch.backends.cudnn.benchmark = False \n",
    "    \n",
    "set_seed(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.sets import load_sets\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317320, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(951959, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317320, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert to tensors\n",
    "from src.models.pytorch import EmbeddingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EmbeddingDataset(X_train, \n",
    "                                      targets=y_train,\n",
    "                                      cat_cols_idx=[0],\n",
    "                                      cont_cols_idx=[1,2,3,4])\n",
    "\n",
    "val_dataset = EmbeddingDataset(X_val, \n",
    "                                      targets=y_val,\n",
    "                                      cat_cols_idx=[0],\n",
    "                                      cont_cols_idx=[1,2,3,4])\n",
    "\n",
    "\n",
    "test_dataset = EmbeddingDataset(X_test,\n",
    "                                     cat_cols_idx=[0],\n",
    "                                     cont_cols_idx=[1,2,3,4],\n",
    "                                     is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element of train_dataset: {'data': [tensor([4918.]), tensor([-3.2047, -2.1777, -0.3572, -0.4001])], 'target': tensor(13)}\n",
      "First element of val_dataset: {'data': [tensor([163.]), tensor([-1.0545, -0.5545, -1.0901, -1.0832])], 'target': tensor(31)}\n",
      "First element of test_dataset: {'data': [tensor([701.]), tensor([ 0.3790,  0.2570,  0.3757, -0.4001])]}\n"
     ]
    }
   ],
   "source": [
    "print(f'First element of train_dataset: {train_dataset[1]}',\n",
    "      f'First element of val_dataset: {val_dataset[1]}',\n",
    "      f'First element of test_dataset: {test_dataset[1]}',sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding example\n",
    "class ClassificationEmbdNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dims, no_of_cont=None):\n",
    "        super(ClassificationEmbdNN, self).__init__()\n",
    "        \n",
    "        self.emb_layers = torch.nn.ModuleList([torch.nn.Embedding(x, y)\n",
    "                                               for x, y in emb_dims])\n",
    "        \n",
    "        no_of_embs = sum([y for x, y in emb_dims])\n",
    "        self.no_of_embs = no_of_embs\n",
    "        self.emb_dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        self.no_of_cont = 0\n",
    "        if no_of_cont:\n",
    "            self.no_of_cont = no_of_cont\n",
    "            self.bn_cont = torch.nn.BatchNorm1d(no_of_cont)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_features=self.no_of_embs + self.no_of_cont, \n",
    "                                   out_features=208)\n",
    "        self.dropout1 = torch.nn.Dropout(0.2)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(208)\n",
    "        self.act1 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(in_features=208, \n",
    "                                   out_features=208)\n",
    "        self.dropout2 = torch.nn.Dropout(0.2)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(208)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        \n",
    "#         self.fc3 = torch.nn.Linear(in_features=256, \n",
    "#                                    out_features=64)\n",
    "#         self.dropout3 = torch.nn.Dropout(0.2)\n",
    "#         self.bn3 = torch.nn.BatchNorm1d(64)\n",
    "#         self.act3 = torch.nn.ReLU()\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(in_features=208, \n",
    "                                   out_features=104)\n",
    "        self.act3 = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, x_cat, x_cont=None):\n",
    "        if self.no_of_embs != 0:\n",
    "            x = [emb_layer(x_cat[:, i])\n",
    "                 for i, emb_layer in enumerate(self.emb_layers)]\n",
    "        \n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_dropout(x)\n",
    "            \n",
    "        if self.no_of_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            \n",
    "            if self.no_of_embs != 0:\n",
    "                x = torch.cat([x, x_cont], 1)\n",
    "            else:\n",
    "                x = x_cont\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        \n",
    "#         x = self.fc3(x)\n",
    "#         x = self.dropout3(x)\n",
    "#         x = self.bn3(x)\n",
    "#         x = self.act3(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.act3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassificationEmbdNN(emb_dims=[[5742, 252]], \n",
    "                             no_of_cont=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationEmbdNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(5742, 252)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=208, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (bn1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=208, out_features=208, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU()\n",
       "  (fc3): Linear(in_features=208, out_features=104, bias=True)\n",
       "  (act3): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.pytorch import get_device\n",
    "\n",
    "device = get_device()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationEmbdNN(\n",
       "  (emb_layers): ModuleList(\n",
       "    (0): Embedding(5742, 252)\n",
       "  )\n",
       "  (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=256, out_features=208, bias=True)\n",
       "  (dropout1): Dropout(p=0.2, inplace=False)\n",
       "  (bn1): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU()\n",
       "  (fc2): Linear(in_features=208, out_features=208, bias=True)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (bn2): BatchNorm1d(208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): ReLU()\n",
       "  (fc3): Linear(in_features=208, out_features=104, bias=True)\n",
       "  (act3): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 300\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_loader = DataLoader(val_dataset,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [tensor([[1897.],\n",
       "          [4918.],\n",
       "          [1701.],\n",
       "          [1963.],\n",
       "          [4863.],\n",
       "          [5448.],\n",
       "          [ 836.],\n",
       "          [ 413.],\n",
       "          [ 370.],\n",
       "          [ 701.],\n",
       "          [1963.],\n",
       "          [2421.],\n",
       "          [2262.],\n",
       "          [3805.],\n",
       "          [5497.],\n",
       "          [ 726.],\n",
       "          [1198.],\n",
       "          [2368.],\n",
       "          [4729.],\n",
       "          [2235.],\n",
       "          [2859.],\n",
       "          [4598.],\n",
       "          [1963.],\n",
       "          [ 177.],\n",
       "          [2642.],\n",
       "          [4843.],\n",
       "          [2885.],\n",
       "          [ 688.],\n",
       "          [4074.],\n",
       "          [3431.],\n",
       "          [3906.],\n",
       "          [4576.],\n",
       "          [4794.],\n",
       "          [2880.],\n",
       "          [3315.],\n",
       "          [1335.],\n",
       "          [4794.],\n",
       "          [2019.],\n",
       "          [ 809.],\n",
       "          [3189.],\n",
       "          [4872.],\n",
       "          [3804.],\n",
       "          [5208.],\n",
       "          [5693.],\n",
       "          [3556.],\n",
       "          [3431.],\n",
       "          [ 154.],\n",
       "          [ 151.],\n",
       "          [  45.],\n",
       "          [4598.],\n",
       "          [2464.],\n",
       "          [4598.],\n",
       "          [1198.],\n",
       "          [3799.],\n",
       "          [2514.],\n",
       "          [3617.],\n",
       "          [1335.],\n",
       "          [2967.],\n",
       "          [5392.],\n",
       "          [2294.],\n",
       "          [3808.],\n",
       "          [5425.],\n",
       "          [4785.],\n",
       "          [ 916.],\n",
       "          [5080.],\n",
       "          [2642.],\n",
       "          [ 701.],\n",
       "          [5381.],\n",
       "          [5608.],\n",
       "          [ 176.],\n",
       "          [2885.],\n",
       "          [4538.],\n",
       "          [ 568.],\n",
       "          [5739.],\n",
       "          [4860.],\n",
       "          [5377.],\n",
       "          [ 596.],\n",
       "          [4743.],\n",
       "          [1963.],\n",
       "          [3841.],\n",
       "          [ 154.],\n",
       "          [4884.],\n",
       "          [3729.],\n",
       "          [4725.],\n",
       "          [4228.],\n",
       "          [ 413.],\n",
       "          [2601.],\n",
       "          [5392.],\n",
       "          [3799.],\n",
       "          [3841.],\n",
       "          [2262.],\n",
       "          [3526.],\n",
       "          [2915.],\n",
       "          [4950.],\n",
       "          [2112.],\n",
       "          [3996.],\n",
       "          [4642.],\n",
       "          [4489.],\n",
       "          [4598.],\n",
       "          [ 411.],\n",
       "          [2922.],\n",
       "          [3577.],\n",
       "          [5364.],\n",
       "          [ 834.],\n",
       "          [ 235.],\n",
       "          [4538.],\n",
       "          [1776.],\n",
       "          [3804.],\n",
       "          [4725.],\n",
       "          [3512.],\n",
       "          [2729.],\n",
       "          [3804.],\n",
       "          [1933.],\n",
       "          [  94.],\n",
       "          [3446.],\n",
       "          [5669.],\n",
       "          [4059.],\n",
       "          [ 151.],\n",
       "          [2207.],\n",
       "          [ 654.],\n",
       "          [1032.],\n",
       "          [3873.],\n",
       "          [2127.],\n",
       "          [ 701.],\n",
       "          [3512.],\n",
       "          [4743.],\n",
       "          [3465.],\n",
       "          [1168.],\n",
       "          [ 886.],\n",
       "          [2262.],\n",
       "          [  48.],\n",
       "          [ 707.],\n",
       "          [5675.],\n",
       "          [3227.],\n",
       "          [2321.],\n",
       "          [5448.],\n",
       "          [ 104.],\n",
       "          [3260.],\n",
       "          [1292.],\n",
       "          [5242.],\n",
       "          [3189.],\n",
       "          [ 163.],\n",
       "          [2470.],\n",
       "          [ 943.],\n",
       "          [5003.],\n",
       "          [1963.],\n",
       "          [4840.],\n",
       "          [2461.],\n",
       "          [4733.],\n",
       "          [ 505.],\n",
       "          [ 163.],\n",
       "          [2461.],\n",
       "          [4794.],\n",
       "          [5582.],\n",
       "          [4934.],\n",
       "          [5553.],\n",
       "          [5607.],\n",
       "          [2249.],\n",
       "          [2698.],\n",
       "          [5531.],\n",
       "          [4105.],\n",
       "          [2616.],\n",
       "          [5679.],\n",
       "          [2367.],\n",
       "          [5392.],\n",
       "          [1556.],\n",
       "          [5334.],\n",
       "          [2207.],\n",
       "          [1343.],\n",
       "          [5448.],\n",
       "          [2523.],\n",
       "          [1629.],\n",
       "          [1933.],\n",
       "          [ 413.],\n",
       "          [ 360.],\n",
       "          [2536.],\n",
       "          [5278.],\n",
       "          [1325.],\n",
       "          [4112.],\n",
       "          [4384.],\n",
       "          [5167.],\n",
       "          [3799.],\n",
       "          [1989.],\n",
       "          [3512.],\n",
       "          [ 654.],\n",
       "          [3194.],\n",
       "          [ 224.],\n",
       "          [3667.],\n",
       "          [ 413.],\n",
       "          [1258.],\n",
       "          [5112.],\n",
       "          [4538.],\n",
       "          [5414.],\n",
       "          [1344.],\n",
       "          [ 151.],\n",
       "          [1266.],\n",
       "          [3189.],\n",
       "          [5381.],\n",
       "          [2316.],\n",
       "          [3099.],\n",
       "          [ 892.],\n",
       "          [5112.],\n",
       "          [3239.],\n",
       "          [ 163.],\n",
       "          [5448.],\n",
       "          [3996.],\n",
       "          [5412.],\n",
       "          [ 375.],\n",
       "          [ 707.],\n",
       "          [ 701.],\n",
       "          [5078.],\n",
       "          [1198.],\n",
       "          [5527.],\n",
       "          [5582.],\n",
       "          [5132.],\n",
       "          [2249.],\n",
       "          [4389.],\n",
       "          [ 437.],\n",
       "          [2318.],\n",
       "          [ 993.],\n",
       "          [ 163.],\n",
       "          [4950.],\n",
       "          [2585.],\n",
       "          [4963.],\n",
       "          [ 235.],\n",
       "          [5531.],\n",
       "          [5242.],\n",
       "          [5607.],\n",
       "          [1893.],\n",
       "          [4524.],\n",
       "          [5448.],\n",
       "          [4435.],\n",
       "          [ 257.],\n",
       "          [ 411.],\n",
       "          [2911.],\n",
       "          [ 360.],\n",
       "          [4743.],\n",
       "          [4489.],\n",
       "          [ 342.],\n",
       "          [1933.],\n",
       "          [ 369.],\n",
       "          [4743.],\n",
       "          [ 235.],\n",
       "          [2514.],\n",
       "          [ 923.],\n",
       "          [2368.],\n",
       "          [5112.],\n",
       "          [5448.],\n",
       "          [1283.],\n",
       "          [3996.],\n",
       "          [1963.],\n",
       "          [4950.],\n",
       "          [4831.],\n",
       "          [2262.],\n",
       "          [4538.],\n",
       "          [1238.],\n",
       "          [2707.],\n",
       "          [5448.],\n",
       "          [5078.],\n",
       "          [2461.],\n",
       "          [4884.],\n",
       "          [5014.],\n",
       "          [4191.],\n",
       "          [5278.],\n",
       "          [2213.],\n",
       "          [ 104.],\n",
       "          [5242.],\n",
       "          [1238.],\n",
       "          [1254.],\n",
       "          [ 163.],\n",
       "          [ 701.],\n",
       "          [1341.],\n",
       "          [ 905.],\n",
       "          [3525.],\n",
       "          [ 260.],\n",
       "          [1963.],\n",
       "          [1933.],\n",
       "          [4831.],\n",
       "          [4598.],\n",
       "          [2562.],\n",
       "          [5014.],\n",
       "          [4538.],\n",
       "          [5224.],\n",
       "          [4831.],\n",
       "          [2853.],\n",
       "          [1963.],\n",
       "          [ 114.],\n",
       "          [2537.],\n",
       "          [2707.],\n",
       "          [ 965.],\n",
       "          [ 177.],\n",
       "          [ 505.],\n",
       "          [5132.],\n",
       "          [1286.],\n",
       "          [5553.],\n",
       "          [2238.],\n",
       "          [ 701.],\n",
       "          [1825.],\n",
       "          [ 802.],\n",
       "          [3804.]]),\n",
       "  tensor([[ 0.3790,  1.0686,  1.8415,  0.9661],\n",
       "          [-3.2047, -2.1777, -0.3572, -0.4001],\n",
       "          [-0.3378,  0.2570, -0.3572, -0.4001],\n",
       "          ...,\n",
       "          [ 0.3790,  0.2570,  0.3757,  0.2830],\n",
       "          [-1.7712, -0.5545, -2.5560, -2.4494],\n",
       "          [-0.3378, -0.5545,  0.3757, -0.4001]])],\n",
       " 'target': tensor([ 11,  13,  92,  18,  93,  21,  92,  98,  11,  73,   9,  82,  11,  11,\n",
       "          61,  31,  60,  78,   3,  12,  12, 102,  11,  84,   5,  81,  18,  12,\n",
       "          37,   3,  47, 102,  84,  19,  84,  39,  12,  51,  26,   4,  12,  98,\n",
       "          42,  43,  30,  83,  12,  42,  99,  83,  17,  46,  58, 103,  99,  14,\n",
       "          98,  92,  98,   6,   2,  19,  61,  86,  40,  84, 103,  36,  17,  18,\n",
       "          76,   9,  26,  21,  40,  11,  25,  12, 103,  61,  12,  47,   7,  46,\n",
       "          12,  37, 100,  98,  14,  89,  94,  14,  42,  89, 100,  36,  98,   4,\n",
       "          51,  94,  44,  14,   9,  89,   7,  26,  76,  12,  60,  18,  65,  35,\n",
       "          55,  49,  12,  49,  44,  33,  12,  14,  70,  98,  12,  92,  52,  12,\n",
       "          82,   5,  26,  14,  24,  68,  50,   9,   6,  14,  20,  19,  75,   9,\n",
       "          19,  13,  14,  24,   7, 103,  14,   4,  14,  98,  76,  14,  84,  79,\n",
       "          21,  42,  96,  21,   2,  83,  44,  49,  65,   2,  60,  14,  99,  19,\n",
       "          98,  98,  67,  93,  18,  16,  37,  57,  37,  26, 102,  82,  92,  58,\n",
       "          73,  61,  12,  14,   0,   1,   2,  98,  84,  20, 103, 103,   7,  25,\n",
       "           9,  24,  17,   6,  53,  92,  94,  40,  14,  14,  70,  12,  14,  31,\n",
       "           2,  86,  41,   2,  19,  12,  25,  17,  55,  80,  76,  14,  46,  73,\n",
       "          25,  79,  16,  96,  98,  55,  21,  43, 103,  43,  53,  40,  14,  12,\n",
       "          47,  11,  92,  12,  89,   1,  75,  35,  11,  80,  22,  89,  11,  19,\n",
       "           4,  11,  12,  89,   9,   9,  12,  40,  47,  11,  80,  37,  14,  26,\n",
       "          12,  42,  26,   1,  16,  98,  23,  47,  21,   9,  14, 103,  83,  43,\n",
       "          12,   9,   2,  21,  12,  18,   4,  82,  92,  61,  42,   7,   2,  74,\n",
       "          89,   2,  16,  17,  22,  44])}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [tensor([[4884.],\n",
       "          [ 163.],\n",
       "          [ 217.],\n",
       "          [ 163.],\n",
       "          [2262.],\n",
       "          [5378.],\n",
       "          [4280.],\n",
       "          [ 413.],\n",
       "          [5003.],\n",
       "          [2461.],\n",
       "          [2461.],\n",
       "          [2316.],\n",
       "          [3841.],\n",
       "          [5066.],\n",
       "          [4453.],\n",
       "          [2461.],\n",
       "          [3341.],\n",
       "          [ 151.],\n",
       "          [4830.],\n",
       "          [2239.],\n",
       "          [5014.],\n",
       "          [3237.],\n",
       "          [2514.],\n",
       "          [5378.],\n",
       "          [5014.],\n",
       "          [5448.],\n",
       "          [3189.],\n",
       "          [5242.],\n",
       "          [2523.],\n",
       "          [1605.],\n",
       "          [2601.],\n",
       "          [5364.],\n",
       "          [ 163.],\n",
       "          [5078.],\n",
       "          [ 224.],\n",
       "          [2689.],\n",
       "          [4132.],\n",
       "          [ 375.],\n",
       "          [ 360.],\n",
       "          [3888.],\n",
       "          [2239.],\n",
       "          [5392.],\n",
       "          [1334.],\n",
       "          [4598.],\n",
       "          [1951.],\n",
       "          [4680.],\n",
       "          [1306.],\n",
       "          [5330.],\n",
       "          [ 154.],\n",
       "          [3804.],\n",
       "          [4950.],\n",
       "          [ 386.],\n",
       "          [2927.],\n",
       "          [4794.],\n",
       "          [4228.],\n",
       "          [1776.],\n",
       "          [3843.],\n",
       "          [ 291.],\n",
       "          [2909.],\n",
       "          [1871.],\n",
       "          [4228.],\n",
       "          [2239.],\n",
       "          [3431.],\n",
       "          [ 509.],\n",
       "          [2262.],\n",
       "          [4453.],\n",
       "          [1168.],\n",
       "          [5370.],\n",
       "          [3057.],\n",
       "          [4538.],\n",
       "          [2989.],\n",
       "          [ 701.],\n",
       "          [3526.],\n",
       "          [ 587.],\n",
       "          [5726.],\n",
       "          [ 235.],\n",
       "          [1506.],\n",
       "          [1933.],\n",
       "          [4077.],\n",
       "          [4262.],\n",
       "          [4794.],\n",
       "          [ 615.],\n",
       "          [ 413.],\n",
       "          [ 177.],\n",
       "          [4743.],\n",
       "          [ 235.],\n",
       "          [2698.],\n",
       "          [4950.],\n",
       "          [2262.],\n",
       "          [2270.],\n",
       "          [2523.],\n",
       "          [3194.],\n",
       "          [4280.],\n",
       "          [3799.],\n",
       "          [4963.],\n",
       "          [3804.],\n",
       "          [3341.],\n",
       "          [5253.],\n",
       "          [1933.],\n",
       "          [ 911.],\n",
       "          [5003.],\n",
       "          [1338.],\n",
       "          [1285.],\n",
       "          [3099.],\n",
       "          [1899.],\n",
       "          [4832.],\n",
       "          [4031.],\n",
       "          [5448.],\n",
       "          [2927.],\n",
       "          [ 836.],\n",
       "          [4863.],\n",
       "          [3841.],\n",
       "          [ 829.],\n",
       "          [5242.],\n",
       "          [1306.],\n",
       "          [5448.],\n",
       "          [5112.],\n",
       "          [1776.],\n",
       "          [2642.],\n",
       "          [1303.],\n",
       "          [4950.],\n",
       "          [4280.],\n",
       "          [4611.],\n",
       "          [2967.],\n",
       "          [2262.],\n",
       "          [ 767.],\n",
       "          [3208.],\n",
       "          [4843.],\n",
       "          [ 154.],\n",
       "          [4357.],\n",
       "          [1314.],\n",
       "          [2927.],\n",
       "          [4226.],\n",
       "          [4748.],\n",
       "          [3809.],\n",
       "          [  48.],\n",
       "          [1325.],\n",
       "          [ 151.],\n",
       "          [1895.],\n",
       "          [ 413.],\n",
       "          [5112.],\n",
       "          [4794.],\n",
       "          [4412.],\n",
       "          [1515.],\n",
       "          [1719.],\n",
       "          [5278.],\n",
       "          [4537.],\n",
       "          [4141.],\n",
       "          [ 596.],\n",
       "          [4540.],\n",
       "          [2112.],\n",
       "          [4241.],\n",
       "          [3996.],\n",
       "          [4619.],\n",
       "          [2601.],\n",
       "          [5582.],\n",
       "          [1936.],\n",
       "          [3799.],\n",
       "          [5527.],\n",
       "          [3596.],\n",
       "          [4485.],\n",
       "          [2523.],\n",
       "          [ 104.],\n",
       "          [1558.],\n",
       "          [2412.],\n",
       "          [ 598.],\n",
       "          [2262.],\n",
       "          [ 235.],\n",
       "          [ 151.],\n",
       "          [4682.],\n",
       "          [4794.],\n",
       "          [ 440.],\n",
       "          [3788.],\n",
       "          [2512.],\n",
       "          [ 716.],\n",
       "          [ 411.],\n",
       "          [2262.],\n",
       "          [1238.],\n",
       "          [1168.],\n",
       "          [3608.],\n",
       "          [4624.],\n",
       "          [5332.],\n",
       "          [4384.],\n",
       "          [ 697.],\n",
       "          [1933.],\n",
       "          [4863.],\n",
       "          [ 151.],\n",
       "          [ 911.],\n",
       "          [4743.],\n",
       "          [2262.],\n",
       "          [ 831.],\n",
       "          [1325.],\n",
       "          [4748.],\n",
       "          [4241.],\n",
       "          [4489.],\n",
       "          [2318.],\n",
       "          [4353.],\n",
       "          [4447.],\n",
       "          [2464.],\n",
       "          [3804.],\n",
       "          [2417.],\n",
       "          [1473.],\n",
       "          [4863.],\n",
       "          [2523.],\n",
       "          [  57.],\n",
       "          [5448.],\n",
       "          [2464.],\n",
       "          [4950.],\n",
       "          [5242.],\n",
       "          [5003.],\n",
       "          [4733.],\n",
       "          [5563.],\n",
       "          [5392.],\n",
       "          [5485.],\n",
       "          [4838.],\n",
       "          [2967.],\n",
       "          [3512.],\n",
       "          [1776.],\n",
       "          [4794.],\n",
       "          [1198.],\n",
       "          [1198.],\n",
       "          [4031.],\n",
       "          [2529.],\n",
       "          [3596.],\n",
       "          [3189.],\n",
       "          [2537.],\n",
       "          [ 151.],\n",
       "          [2601.],\n",
       "          [ 413.],\n",
       "          [4489.],\n",
       "          [1728.],\n",
       "          [2536.],\n",
       "          [1414.],\n",
       "          [2262.],\n",
       "          [5278.],\n",
       "          [ 413.],\n",
       "          [5003.],\n",
       "          [4972.],\n",
       "          [1318.],\n",
       "          [1963.],\n",
       "          [2668.],\n",
       "          [3804.],\n",
       "          [3872.],\n",
       "          [4838.],\n",
       "          [ 163.],\n",
       "          [4963.],\n",
       "          [5392.],\n",
       "          [2464.],\n",
       "          [ 151.],\n",
       "          [ 701.],\n",
       "          [1314.],\n",
       "          [4863.],\n",
       "          [ 670.],\n",
       "          [1342.],\n",
       "          [5737.],\n",
       "          [3906.],\n",
       "          [5553.],\n",
       "          [4489.],\n",
       "          [4489.],\n",
       "          [ 413.],\n",
       "          [ 163.],\n",
       "          [ 363.],\n",
       "          [3847.],\n",
       "          [5527.],\n",
       "          [4950.],\n",
       "          [1933.],\n",
       "          [5529.],\n",
       "          [3677.],\n",
       "          [3624.],\n",
       "          [1198.],\n",
       "          [1330.],\n",
       "          [1334.],\n",
       "          [3853.],\n",
       "          [ 515.],\n",
       "          [5132.],\n",
       "          [ 704.],\n",
       "          [4838.],\n",
       "          [4838.],\n",
       "          [3294.],\n",
       "          [4489.],\n",
       "          [  97.],\n",
       "          [1198.],\n",
       "          [ 701.],\n",
       "          [3189.],\n",
       "          [4950.],\n",
       "          [4939.],\n",
       "          [3128.],\n",
       "          [3692.],\n",
       "          [4743.],\n",
       "          [ 767.],\n",
       "          [2262.],\n",
       "          [ 701.],\n",
       "          [5115.],\n",
       "          [ 596.],\n",
       "          [4729.],\n",
       "          [ 819.],\n",
       "          [5364.],\n",
       "          [ 707.],\n",
       "          [2461.],\n",
       "          [1238.]]),\n",
       "  tensor([[ 0.3790,  0.2570,  0.3757,  0.2830],\n",
       "          [-1.0545, -0.5545, -1.0901, -1.0832],\n",
       "          [-0.3378,  0.2570, -0.3572,  0.2830],\n",
       "          ...,\n",
       "          [-0.3378,  1.0686, -1.8230, -1.0832],\n",
       "          [ 0.3790,  1.0686,  1.1086,  0.9661],\n",
       "          [-0.3378,  0.2570,  0.3757, -0.4001]])],\n",
       " 'target': tensor([ 79,  31,  80,  15,  84,   0,  65,  11,  79,  23,  89,  93,  61,  27,\n",
       "          53,  84,  65,  33,  14, 103,  86,  44,  80,   0,  12,   9,  19,  14,\n",
       "          68,   1,  16,  98,  77,  14,   3,  18,  84,  12,  81,  44,  17,  98,\n",
       "          26,  46,  82,  17,  74,  17,  16,  20,   2,  66,   3,  14,   9,  76,\n",
       "          14,   2,  44,  60,  89,  21,  60,  12,  11,  31,   7,  17,  15,  24,\n",
       "          65,  31,   2,  61,  36,   4,  79,  14,   1,  92,  86,  47,  14,   2,\n",
       "          14,  67,  16,  17,  90,  83,  67,  35,  37,  24,  17,  60,  65,  32,\n",
       "          42,  24,  12,  58,  26,  17,   7,   6,  13, 103,  60,  92,  67,  26,\n",
       "          25,   9,  74,  12,  66,  16,  42,  26,  17,  37,  18,  29,  94,  74,\n",
       "          37,  37,  16,  61,  63,  60,  36,  55,  45,  24,  39,  31,  58,  16,\n",
       "          25,  17,  36,  47,  23,  37,  94,   6,  98,  12,  65,  12,   9,  20,\n",
       "           9,  16,   1,  16,  65,  51,  16,  68,  39,  14,  11,  14,  90,  86,\n",
       "         102, 102,  99,  61,   2,  52,  18,  94,  94,  89,  17,  70,  69,  49,\n",
       "          55,  14,   9,   1, 102,  24,  86,  94,  92,  39,  94,  98,  66,  49,\n",
       "           5,  90,  17,  40,  17,  89,  78,  77,  76,  12,  68,  19,  89,  43,\n",
       "          12,  26,  98,  90,  19,  25,  68,  76,  94,  22,  39,   1,  47,  51,\n",
       "           2,  81, 102,  16, 103,   7,  82,  89,  60,  11,  37,  19,  43,   1,\n",
       "          58,  25,   9,  60,   4,  12,  76,  42,  25,  31,  17,   4,  63,  37,\n",
       "          36,  24,  37,  20,   9,  60,  16,  89,   3,  12,   5,  65,   5,  18,\n",
       "          89,  14,  59,  29,  75,  86,   9,  77,  42,  89,  19,   2,  84,  83,\n",
       "           9,  39,  82,  16,  14,  16,  84,   1,  12,  74,   9,  60,  44,  25,\n",
       "          66,  11,   0,   9,  89,  90])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(model, train_loader, valid_loader,\n",
    "                  loss_func, optimizer, n_epochs=20,\n",
    "                  saved_model='model.pt'):\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses = list()\n",
    "    valid_losses = list()\n",
    "    \n",
    "    valid_loss_min = np.Inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "#         train_auc = 0.0\n",
    "#         valid_auc = 0.0\n",
    "        \n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long),\n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float))\n",
    "            \n",
    "            \n",
    "            loss = loss_func(output, batch['target'].to(device, \n",
    "                                                        dtype=torch.long))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Calculate global accuracy\n",
    "            train_acc += (output.argmax(1) == batch['target']).sum().item()\n",
    "#             train_auc += roc_auc_score(batch['target'].cpu().numpy(),\n",
    "#                                                output.detach().cpu().numpy(),\n",
    "#                                                multi_class = \"ovo\")\n",
    "\n",
    "            train_loss += loss.item() * batch['data'][0].size(0)  #!!!\n",
    "    \n",
    "\n",
    "        model.eval()\n",
    "        for batch in tqdm(valid_loader):\n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long),\n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float))\n",
    "            \n",
    "            \n",
    "            loss = loss_func(output, batch['target'].to(device, \n",
    "                                                        dtype=torch.long))\n",
    "            \n",
    "#             valid_auc += roc_auc_score(batch['target'].cpu().numpy(),\n",
    "#                                                output.detach().cpu().numpy(),\n",
    "#                                                multi_class = \"ovo\")\n",
    "            valid_loss += loss.item() * batch['data'][0].size(0)  #!!!\n",
    "            # Calculate global accuracy\n",
    "            valid_acc += (output.argmax(1) == batch['target']).sum().item()\n",
    "        \n",
    "#         train_loss = np.sqrt(train_loss / len(train_loader.sampler.indices))\n",
    "#         valid_loss = np.sqrt(valid_loss / len(valid_loader.sampler.indices))\n",
    "\n",
    "#         train_auc = train_auc / len(train_loader)\n",
    "#         valid_auc = valid_auc / len(valid_loader)\n",
    "        \n",
    "#         train_losses.append(train_loss)\n",
    "#         valid_losses.append(valid_loss)\n",
    "\n",
    "        print('Epoch: {}. Training loss: {:.6f}. Validation loss: {:.6f}'\n",
    "              .format(epoch, train_loss, valid_loss))\n",
    "        print('Training AUC: {:.6f}. Validation AUC: {:.6f}'\n",
    "              .format(train_acc, valid_acc))\n",
    "        \n",
    "        if valid_loss < valid_loss_min:  # let's save the best weights to use them in prediction\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model...'\n",
    "                  .format(valid_loss_min, valid_loss))\n",
    "            \n",
    "            torch.save(model.state_dict(), saved_model)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6281a159dc4acda555554e610254c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:48: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0dee03b97594caab868a35abf6f7fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0. Training loss: 4421724.604657. Validation loss: 1473862.318449\n",
      "Training AUC: 5908.000000. Validation AUC: 2346.000000\n",
      "Validation loss decreased (inf --> 1473862.318449). Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76622ec8d3e44ed8b7d24608b1dbcb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e448e268b0b0414a9ed166054c16bd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1. Training loss: 4421724.043646. Validation loss: 1473859.110718\n",
      "Training AUC: 5853.000000. Validation AUC: 2390.000000\n",
      "Validation loss decreased (1473862.318449 --> 1473859.110718). Saving model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2847909bf044a869c9c63438eafadfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d2d17a48df4bb8ae28f66dd2124838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2. Training loss: 4421721.100763. Validation loss: 1473863.261547\n",
      "Training AUC: 5896.000000. Validation AUC: 2349.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e4fdcb2b6d40f591cdfcd3aa7ec956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bfc3b55cc34c648d1af1764ac5bb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3. Training loss: 4421726.304363. Validation loss: 1473860.931282\n",
      "Training AUC: 5861.000000. Validation AUC: 2359.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa67e105d6234870a7ebe5a0846fbb94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e28d89795b45209cbcb31aa8949a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4. Training loss: 4421723.953760. Validation loss: 1473859.757814\n",
      "Training AUC: 5849.000000. Validation AUC: 2359.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3b0017a4ef4d73bdb1bfab01bad09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1021df4bcb794dbf9cd58961e9582e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5. Training loss: 4421724.728816. Validation loss: 1473861.321592\n",
      "Training AUC: 5849.000000. Validation AUC: 2317.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa48da87b5914108a1cd65f0dcfa73f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ad57026534429b94d2c8826e6458f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 6. Training loss: 4421720.038199. Validation loss: 1473861.021938\n",
      "Training AUC: 5697.000000. Validation AUC: 2417.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e7e26de827450e9c0095906c11ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768a1a632c64478287cb487d5008f5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 7. Training loss: 4421728.686065. Validation loss: 1473860.797329\n",
      "Training AUC: 5810.000000. Validation AUC: 2387.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9ebd0bcf714d9ca6b061c269bc0f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f09b60c7404100a972d22fa5cfe619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 8. Training loss: 4421722.932936. Validation loss: 1473860.643997\n",
      "Training AUC: 5801.000000. Validation AUC: 2354.000000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c8a85a7acf484394e6b07784e799b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3174.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3758099e398047379197efa3a5f0e401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 9. Training loss: 4421724.683504. Validation loss: 1473858.867426\n",
      "Training AUC: 5926.000000. Validation AUC: 2361.000000\n",
      "Validation loss decreased (1473859.110718 --> 1473858.867426). Saving model...\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = train_network(model=model, \n",
    "                                           train_loader=train_loader, \n",
    "                                           valid_loader=valid_loader, \n",
    "                                           loss_func=criterion, \n",
    "                                           optimizer=optimizer,\n",
    "                                           n_epochs=N_EPOCHS, \n",
    "                                           saved_model='../models/embed_3layers.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forgot to divide the loss and accuracy by length of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 19.75%\n",
      "Validation Accuracy: 7.87%\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: {:.2f}%'.format(5926.0/300.0))\n",
    "print('Validation Accuracy: {:.2f}%'.format(2361.0/300.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = None\n",
    "        \n",
    "        for i, batch in enumerate(tqdm(data_loader)):   \n",
    "            \n",
    "            output = model(batch['data'][0].to(device, \n",
    "                                               dtype=torch.long), \n",
    "                           batch['data'][1].to(device, \n",
    "                                               dtype=torch.float)).cpu().numpy()\n",
    "            \n",
    "            if i == 0:\n",
    "                predictions = output\n",
    "                \n",
    "            else: \n",
    "                \n",
    "                predictions = np.vstack((predictions, output))\n",
    "                \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e30f83974849bdb03fdd520ff09f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1058.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:73: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/embed_3layers.pt'))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=BATCH_SIZE)\n",
    "\n",
    "nn_predictions = predict(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01260628, 0.00742896, 0.00644201, ..., 0.00936545, 0.01223338,\n",
       "        0.00800614],\n",
       "       [0.00870188, 0.00563232, 0.01582166, ..., 0.0086471 , 0.01082051,\n",
       "        0.0085842 ],\n",
       "       [0.00938711, 0.0065556 , 0.01092372, ..., 0.00528657, 0.00847999,\n",
       "        0.01576285],\n",
       "       ...,\n",
       "       [0.01357877, 0.00672801, 0.0100839 , ..., 0.00834409, 0.00656633,\n",
       "        0.01293461],\n",
       "       [0.00949264, 0.00695431, 0.01194292, ..., 0.01046819, 0.00798348,\n",
       "        0.00741773],\n",
       "       [0.01299331, 0.00624016, 0.01440495, ..., 0.00893319, 0.00758309,\n",
       "        0.01268085]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = (nn_predictions.argmax(1) == y_test).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.533333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4919978611119817"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute other metrics\n",
    "roc_auc_score(y_test,nn_predictions, multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83 102  11 ...  43   9  14]\n",
      "[73 50 80 ... 12 32 99]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(nn_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cr_to_dataframe(report_dict:dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts the dictionary format of the Classification Report (CR) to a\n",
    "    dataframe for easy of sorting\n",
    "    :param report_dict: The dictionary returned by \n",
    "    sklearn.metrics.classification_report.\n",
    "    :return: Returns a dataframe of the same information.\n",
    "    \"\"\"\n",
    "    beer_style = list(report_dict.keys())\n",
    "    beer_style.remove('accuracy')\n",
    "    beer_style.remove('macro avg')\n",
    "    beer_style.remove('weighted avg')\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    support = []\n",
    "    for key, value in report_dict.items():\n",
    "        if key not in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "            precision.append(value['precision'])\n",
    "            recall.append(value['recall'])\n",
    "            f1.append(value['f1-score'])\n",
    "            support.append(value['support'])\n",
    "    result = pd.DataFrame({'beer_style': beer_style,\n",
    "                           'precision': precision,\n",
    "                           'recall': recall,\n",
    "                           'f1': f1,\n",
    "                           'support': support})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "label_encoders = load('../models/label_encoders.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              beer_style  precision    recall        f1  \\\n",
      "0                                Altbier   0.004481  0.013342  0.006709   \n",
      "1                 American Adjunct Lager   0.000000  0.000000  0.000000   \n",
      "2               American Amber / Red Ale   0.031808  0.013229  0.018686   \n",
      "3             American Amber / Red Lager   0.141541  0.091302  0.111002   \n",
      "4                    American Barleywine   0.001211  0.000184  0.000319   \n",
      "5                     American Black Ale   0.005499  0.025257  0.009032   \n",
      "6                    American Blonde Ale   0.008511  0.000775  0.001421   \n",
      "7                     American Brown Ale   0.000000  0.000000  0.000000   \n",
      "8                American Dark Wheat Ale   0.000000  0.000000  0.000000   \n",
      "9         American Double / Imperial IPA   0.000000  0.000000  0.000000   \n",
      "10    American Double / Imperial Pilsner   0.018263  0.117391  0.031609   \n",
      "11      American Double / Imperial Stout   0.135552  0.027775  0.046103   \n",
      "12                          American IPA   0.049180  0.000897  0.001761   \n",
      "13                  American Malt Liquor   0.006456  0.036697  0.010980   \n",
      "14               American Pale Ale (APA)   0.022472  0.000951  0.001825   \n",
      "15                   American Pale Lager   0.000000  0.000000  0.000000   \n",
      "16               American Pale Wheat Ale   0.000000  0.000000  0.000000   \n",
      "17                       American Porter   0.000000  0.000000  0.000000   \n",
      "18                        American Stout   0.004739  0.000406  0.000747   \n",
      "19                   American Strong Ale   0.000000  0.000000  0.000000   \n",
      "20                     American Wild Ale   0.000000  0.000000  0.000000   \n",
      "21                         Baltic Porter   0.000000  0.000000  0.000000   \n",
      "22                      Belgian Dark Ale   0.000719  0.000783  0.000750   \n",
      "23                           Belgian IPA   0.009583  0.037619  0.015275   \n",
      "24                      Belgian Pale Ale   0.000000  0.000000  0.000000   \n",
      "25               Belgian Strong Dark Ale   0.022131  0.010692  0.014418   \n",
      "26               Belgian Strong Pale Ale   0.000000  0.000000  0.000000   \n",
      "27                    Berliner Weissbier   0.000000  0.000000  0.000000   \n",
      "28       Bire de Champagne / Bire Brut   0.000000  0.000000  0.000000   \n",
      "29                        Bire de Garde   0.000000  0.000000  0.000000   \n",
      "30                           Black & Tan   0.000000  0.000000  0.000000   \n",
      "31                                  Bock   0.000000  0.000000  0.000000   \n",
      "32                               Braggot   0.001059  0.288991  0.002111   \n",
      "33        California Common / Steam Beer   0.000000  0.000000  0.000000   \n",
      "34                            Chile Beer   0.000000  0.000000  0.000000   \n",
      "35                             Cream Ale   0.000000  0.000000  0.000000   \n",
      "36                        Czech Pilsener   0.000000  0.000000  0.000000   \n",
      "37                            Doppelbock   0.000000  0.000000  0.000000   \n",
      "38             Dortmunder / Export Lager   0.001350  0.002060  0.001631   \n",
      "39                                Dubbel   0.002083  0.000247  0.000442   \n",
      "40                          Dunkelweizen   0.000000  0.000000  0.000000   \n",
      "41                               Eisbock   0.000000  0.000000  0.000000   \n",
      "42                    English Barleywine   0.013514  0.001099  0.002033   \n",
      "43                        English Bitter   0.002892  0.005737  0.003845   \n",
      "44                     English Brown Ale   0.016615  0.006918  0.009768   \n",
      "45                 English Dark Mild Ale   0.000000  0.000000  0.000000   \n",
      "46          English India Pale Ale (IPA)   0.014463  0.002183  0.003794   \n",
      "47                      English Pale Ale   0.002258  0.001068  0.001451   \n",
      "48                 English Pale Mild Ale   0.000000  0.000000  0.000000   \n",
      "49                        English Porter   0.000000  0.000000  0.000000   \n",
      "50                         English Stout   0.000151  0.003257  0.000288   \n",
      "51                    English Strong Ale   0.000000  0.000000  0.000000   \n",
      "52                       Euro Dark Lager   0.000000  0.000000  0.000000   \n",
      "53                       Euro Pale Lager   0.008130  0.000271  0.000525   \n",
      "54                     Euro Strong Lager   0.009658  0.147330  0.018128   \n",
      "55   Extra Special / Strong Bitter (ESB)   0.000000  0.000000  0.000000   \n",
      "56                                  Faro   0.000000  0.000000  0.000000   \n",
      "57                    Flanders Oud Bruin   0.001429  0.001043  0.001206   \n",
      "58                      Flanders Red Ale   0.000000  0.000000  0.000000   \n",
      "59                Foreign / Export Stout   0.000000  0.000000  0.000000   \n",
      "60                Fruit / Vegetable Beer   0.000000  0.000000  0.000000   \n",
      "61                       German Pilsener   0.000000  0.000000  0.000000   \n",
      "62                                  Gose   0.000000  0.000000  0.000000   \n",
      "63                                Gueuze   0.000000  0.000000  0.000000   \n",
      "64                              Happoshu   0.000000  0.000000  0.000000   \n",
      "65                            Hefeweizen   0.000000  0.000000  0.000000   \n",
      "66                  Herbed / Spiced Beer   0.000000  0.000000  0.000000   \n",
      "67                       Irish Dry Stout   0.000000  0.000000  0.000000   \n",
      "68                         Irish Red Ale   0.000000  0.000000  0.000000   \n",
      "69                   Japanese Rice Lager   0.000000  0.000000  0.000000   \n",
      "70            Keller Bier / Zwickel Bier   0.000000  0.000000  0.000000   \n",
      "71                         Kristalweizen   0.000000  0.000000  0.000000   \n",
      "72                                 Kvass   0.000000  0.000000  0.000000   \n",
      "73                                Klsch   0.005144  0.255635  0.010086   \n",
      "74                        Lambic - Fruit   0.000000  0.000000  0.000000   \n",
      "75                    Lambic - Unblended   0.000000  0.000000  0.000000   \n",
      "76                           Light Lager   0.000000  0.000000  0.000000   \n",
      "77                      Low Alcohol Beer   0.000000  0.000000  0.000000   \n",
      "78                 Maibock / Helles Bock   0.000636  0.003802  0.001089   \n",
      "79                    Milk / Sweet Stout   0.007124  0.003033  0.004254   \n",
      "80                   Munich Dunkel Lager   0.002672  0.013915  0.004483   \n",
      "81                   Munich Helles Lager   0.006805  0.010632  0.008299   \n",
      "82                  Mrzen / Oktoberfest   0.014706  0.000425  0.000826   \n",
      "83                         Oatmeal Stout   0.000000  0.000000  0.000000   \n",
      "84                               Old Ale   0.000000  0.000000  0.000000   \n",
      "85                           Pumpkin Ale   0.000000  0.000000  0.000000   \n",
      "86                      Quadrupel (Quad)   0.000000  0.000000  0.000000   \n",
      "87                             Rauchbier   0.000000  0.000000  0.000000   \n",
      "88                            Roggenbier   0.000000  0.000000  0.000000   \n",
      "89                Russian Imperial Stout   0.000000  0.000000  0.000000   \n",
      "90                              Rye Beer   0.000000  0.000000  0.000000   \n",
      "91                                 Sahti   0.000000  0.000000  0.000000   \n",
      "92                Saison / Farmhouse Ale   0.022814  0.021677  0.022231   \n",
      "93                           Schwarzbier   0.008842  0.020145  0.012289   \n",
      "94                Scotch Ale / Wee Heavy   0.021978  0.002874  0.005084   \n",
      "95                          Scottish Ale   0.001009  0.007123  0.001768   \n",
      "96   Scottish Gruit / Ancient Herbed Ale   0.000000  0.000000  0.000000   \n",
      "97                           Smoked Beer   0.000000  0.000000  0.000000   \n",
      "98                                Tripel   0.040000  0.004123  0.007476   \n",
      "99                          Vienna Lager   0.000386  0.000548  0.000453   \n",
      "100                           Weizenbock   0.000000  0.000000  0.000000   \n",
      "101                            Wheatwine   0.000000  0.000000  0.000000   \n",
      "102                        Winter Warmer   0.000000  0.000000  0.000000   \n",
      "103                              Witbier   0.018517  0.052798  0.027419   \n",
      "\n",
      "     support  \n",
      "0       1574  \n",
      "1       6047  \n",
      "2       9298  \n",
      "3       1851  \n",
      "4       5439  \n",
      "5       2336  \n",
      "6       2579  \n",
      "7       5026  \n",
      "8        284  \n",
      "9      17309  \n",
      "10      1150  \n",
      "11     10117  \n",
      "12     23419  \n",
      "13       763  \n",
      "14     12617  \n",
      "15      1777  \n",
      "16      4979  \n",
      "17     10009  \n",
      "18      4930  \n",
      "19      6375  \n",
      "20      3495  \n",
      "21      2362  \n",
      "22      1277  \n",
      "23      2419  \n",
      "24      3932  \n",
      "25      7576  \n",
      "26      6203  \n",
      "27       709  \n",
      "28       224  \n",
      "29      1330  \n",
      "30       487  \n",
      "31      2315  \n",
      "32       218  \n",
      "33       807  \n",
      "34       460  \n",
      "35      1017  \n",
      "36      2557  \n",
      "37      4391  \n",
      "38       971  \n",
      "39      4048  \n",
      "40      1411  \n",
      "41       553  \n",
      "42      2730  \n",
      "43      1743  \n",
      "44      3903  \n",
      "45       499  \n",
      "46      3206  \n",
      "47      4680  \n",
      "48       134  \n",
      "49      2269  \n",
      "50       614  \n",
      "51       983  \n",
      "52       893  \n",
      "53      3688  \n",
      "54       543  \n",
      "55      3476  \n",
      "56       102  \n",
      "57       959  \n",
      "58      1307  \n",
      "59      1145  \n",
      "60      6713  \n",
      "61      4333  \n",
      "62       129  \n",
      "63      1195  \n",
      "64        50  \n",
      "65      5572  \n",
      "66      2071  \n",
      "67      2507  \n",
      "68      1546  \n",
      "69       290  \n",
      "70       514  \n",
      "71       459  \n",
      "72        70  \n",
      "73      1686  \n",
      "74      2122  \n",
      "75       220  \n",
      "76      2794  \n",
      "77       228  \n",
      "78      2104  \n",
      "79      2638  \n",
      "80      1581  \n",
      "81      1599  \n",
      "82      4706  \n",
      "83      3600  \n",
      "84      2998  \n",
      "85      3019  \n",
      "86      3716  \n",
      "87       804  \n",
      "88       109  \n",
      "89     10734  \n",
      "90      2057  \n",
      "91       208  \n",
      "92      6320  \n",
      "93      1936  \n",
      "94      3479  \n",
      "95      1825  \n",
      "96       558  \n",
      "97       595  \n",
      "98      6063  \n",
      "99      1825  \n",
      "100     1900  \n",
      "101      769  \n",
      "102     4140  \n",
      "103     6023  \n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = 150\n",
    "report_dict = classification_report(label_encoders['beer_style'].inverse_transform(y_test),\n",
    "                                    label_encoders['beer_style'].inverse_transform(nn_predictions.argmax(1)),\n",
    "                                    output_dict=True)\n",
    "report_df = convert_cr_to_dataframe(report_dict)\n",
    "print(report_df)\n",
    "#classification_report(y_test, nn_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.to_csv('../data/processed/class_report.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"../models/model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Klsch',\n",
       " 'English Stout',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Munich Helles Lager',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'English Stout',\n",
       " 'Sahti',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Faro',\n",
       " 'Kristalweizen',\n",
       " 'Low Alcohol Beer',\n",
       " 'American Black Ale',\n",
       " 'Low Alcohol Beer',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Ale',\n",
       " 'Dortmunder / Export Lager',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Schwarzbier',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Braggot',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Witbier',\n",
       " 'Munich Helles Lager',\n",
       " 'Japanese Rice Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Milk / Sweet Stout',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Vienna Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Scottish Ale',\n",
       " 'Japanese Rice Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'English Pale Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Scottish Ale',\n",
       " 'Japanese Rice Lager',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Witbier',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Scottish Ale',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'English Brown Ale',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'English Porter',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Japanese Rice Lager',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'American Amber / Red Ale',\n",
       " 'Schwarzbier',\n",
       " 'Japanese Rice Lager',\n",
       " 'American Stout',\n",
       " 'Euro Strong Lager',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Vienna Lager',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'American Malt Liquor',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'American Stout',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Tripel',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Altbier',\n",
       " 'Altbier',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Herbed / Spiced Beer',\n",
       " 'Vienna Lager',\n",
       " 'Witbier',\n",
       " 'English Stout',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Klsch',\n",
       " 'English Pale Ale',\n",
       " 'Altbier',\n",
       " 'English Stout',\n",
       " 'Witbier',\n",
       " 'American Malt Liquor',\n",
       " 'American Amber / Red Ale',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'American Black Ale',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Belgian IPA',\n",
       " 'Schwarzbier',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'Munich Helles Lager',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Sahti',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'American IPA',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Schwarzbier',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'American Amber / Red Lager',\n",
       " 'Belgian IPA',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Low Alcohol Beer',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'American Blonde Ale',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'American Amber / Red Ale',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Schwarzbier',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Munich Helles Lager',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English Pale Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Belgian Dark Ale',\n",
       " 'English Stout',\n",
       " 'Herbed / Spiced Beer',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'English Brown Ale',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Barleywine',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Altbier',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'English India Pale Ale (IPA)',\n",
       " 'Klsch',\n",
       " 'Flanders Red Ale',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Gose',\n",
       " 'American Amber / Red Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Schwarzbier',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'American Amber / Red Ale',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Lager',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Vienna Lager',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Altbier',\n",
       " 'Altbier',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'English Bitter',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Altbier',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Flanders Oud Bruin',\n",
       " 'Altbier',\n",
       " 'English Stout',\n",
       " 'American Black Ale',\n",
       " 'English Stout',\n",
       " 'Altbier',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Sahti',\n",
       " 'Klsch',\n",
       " 'Black & Tan',\n",
       " 'Tripel',\n",
       " 'Braggot',\n",
       " 'Gose',\n",
       " 'Witbier',\n",
       " 'English Brown Ale',\n",
       " 'Klsch',\n",
       " 'American Pale Ale (APA)',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Altbier',\n",
       " 'Klsch',\n",
       " 'English Brown Ale',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Altbier',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Milk / Sweet Stout',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Belgian Dark Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Witbier',\n",
       " 'Japanese Rice Lager',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Altbier',\n",
       " 'Klsch',\n",
       " 'Sahti',\n",
       " 'Braggot',\n",
       " 'Euro Strong Lager',\n",
       " 'Scottish Ale',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Euro Dark Lager',\n",
       " 'American IPA',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Ale',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'California Common / Steam Beer',\n",
       " 'American Malt Liquor',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Gueuze',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Euro Strong Lager',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English India Pale Ale (IPA)',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Low Alcohol Beer',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Belgian Dark Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Schwarzbier',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'Sahti',\n",
       " 'Braggot',\n",
       " 'American Amber / Red Ale',\n",
       " 'Braggot',\n",
       " 'Extra Special / Strong Bitter (ESB)',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Gose',\n",
       " 'English Stout',\n",
       " 'Flanders Oud Bruin',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Sahti',\n",
       " 'Black & Tan',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'Euro Dark Lager',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Belgian Dark Ale',\n",
       " 'Japanese Rice Lager',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'American Amber / Red Lager',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Euro Strong Lager',\n",
       " 'Braggot',\n",
       " 'Sahti',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Altbier',\n",
       " 'American Malt Liquor',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Belgian Dark Ale',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'American Black Ale',\n",
       " 'Euro Strong Lager',\n",
       " 'American Amber / Red Ale',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Altbier',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Belgian Dark Ale',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Black & Tan',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Altbier',\n",
       " 'Braggot',\n",
       " 'Dortmunder / Export Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Belgian IPA',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Japanese Rice Lager',\n",
       " 'Altbier',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Japanese Rice Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Gose',\n",
       " 'Euro Strong Lager',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Scottish Ale',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'American Barleywine',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Japanese Rice Lager',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Braggot',\n",
       " 'Flanders Red Ale',\n",
       " 'Schwarzbier',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Klsch',\n",
       " 'Sahti',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Braggot',\n",
       " 'Low Alcohol Beer',\n",
       " 'Belgian IPA',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Witbier',\n",
       " 'Belgian IPA',\n",
       " 'Witbier',\n",
       " 'Faro',\n",
       " 'English Pale Ale',\n",
       " 'American Black Ale',\n",
       " 'American Malt Liquor',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Japanese Rice Lager',\n",
       " 'Tripel',\n",
       " 'Quadrupel (Quad)',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Schwarzbier',\n",
       " 'Black & Tan',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'American Malt Liquor',\n",
       " 'Altbier',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Scottish Ale',\n",
       " 'Vienna Lager',\n",
       " 'Dortmunder / Export Lager',\n",
       " 'American Malt Liquor',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Scotch Ale / Wee Heavy',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Klsch',\n",
       " 'Japanese Rice Lager',\n",
       " 'Sahti',\n",
       " 'Vienna Lager',\n",
       " 'American Black Ale',\n",
       " 'Herbed / Spiced Beer',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'American IPA',\n",
       " 'American Black Ale',\n",
       " 'Vienna Lager',\n",
       " 'Belgian IPA',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Japanese Rice Lager',\n",
       " 'Braggot',\n",
       " 'English Brown Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Munich Helles Lager',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Vienna Lager',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'American Amber / Red Ale',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'American Black Ale',\n",
       " 'Belgian Pale Ale',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Lager',\n",
       " 'Klsch',\n",
       " 'Munich Helles Lager',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Schwarzbier',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'American Malt Liquor',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'English Stout',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English Bitter',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Scottish Ale',\n",
       " 'Witbier',\n",
       " 'Japanese Rice Lager',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'California Common / Steam Beer',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'Schwarzbier',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'English Pale Ale',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'English Pale Ale',\n",
       " 'American Malt Liquor',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'Munich Helles Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Sahti',\n",
       " 'Klsch',\n",
       " 'Japanese Rice Lager',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'Braggot',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'English Stout',\n",
       " 'English Pale Ale',\n",
       " 'Klsch',\n",
       " 'American Malt Liquor',\n",
       " 'American Malt Liquor',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Braggot',\n",
       " 'English Stout',\n",
       " 'Klsch',\n",
       " 'Munich Helles Lager',\n",
       " 'Braggot',\n",
       " 'Munich Helles Lager',\n",
       " 'Scottish Ale',\n",
       " 'American Black Ale',\n",
       " 'Witbier',\n",
       " 'Euro Strong Lager',\n",
       " 'Lambic - Fruit',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Altbier',\n",
       " 'American Malt Liquor',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'California Common / Steam Beer',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Vienna Lager',\n",
       " 'Klsch',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'American Malt Liquor',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Ale',\n",
       " 'Euro Strong Lager',\n",
       " 'Witbier',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Scottish Ale',\n",
       " 'American Black Ale',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'American IPA',\n",
       " 'Klsch',\n",
       " 'Japanese Rice Lager',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Scottish Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Bitter',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Stout',\n",
       " 'Kristalweizen',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Low Alcohol Beer',\n",
       " 'Klsch',\n",
       " 'Black & Tan',\n",
       " 'Klsch',\n",
       " 'Munich Helles Lager',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Belgian Strong Dark Ale',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " 'Scottish Ale',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Flanders Oud Bruin',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Klsch',\n",
       " 'Sahti',\n",
       " 'Belgian IPA',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Maibock / Helles Bock',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'American Barleywine',\n",
       " 'Braggot',\n",
       " 'Altbier',\n",
       " 'Klsch',\n",
       " 'American Double / Imperial Pilsner',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'Maibock / Helles Bock',\n",
       " 'English Strong Ale',\n",
       " 'Klsch',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Scottish Ale',\n",
       " 'English Stout',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'Euro Strong Lager',\n",
       " 'Braggot',\n",
       " 'Vienna Lager',\n",
       " 'Braggot',\n",
       " 'Vienna Lager',\n",
       " 'English Bitter',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Euro Strong Lager',\n",
       " 'Klsch',\n",
       " 'American Amber / Red Ale',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Stout',\n",
       " 'American Black Ale',\n",
       " 'Braggot',\n",
       " 'Braggot',\n",
       " 'Saison / Farmhouse Ale',\n",
       " 'English Bitter',\n",
       " 'Scottish Gruit / Ancient Herbed Ale',\n",
       " 'Japanese Rice Lager',\n",
       " 'Braggot',\n",
       " 'Witbier',\n",
       " 'Braggot',\n",
       " 'American Double / Imperial Stout',\n",
       " 'Gose',\n",
       " 'Witbier',\n",
       " 'Witbier',\n",
       " 'Klsch',\n",
       " 'Witbier',\n",
       " 'Schwarzbier',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'English Pale Ale',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Braggot',\n",
       " 'Munich Dunkel Lager',\n",
       " 'Braggot',\n",
       " 'Klsch',\n",
       " 'Klsch',\n",
       " 'Belgian IPA',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoders['beer_style'].inverse_transform(nn_predictions.argmax(1)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
